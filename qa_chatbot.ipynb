{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# STEP 1: SETUP & IMPORTS\n",
    "# ---------------------------------------------------------\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, TokenTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Load Environment Variables (API Keys)\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API Key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Please set your OPENAI_API_KEY in the .env file\")\n",
    "\n",
    "print(\"Libraries imported and Environment loaded successfully.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 2: DATA LOADING & PREPROCESSING\n",
    "# ---------------------------------------------------------\n",
    "def load_and_split_documents(pdf_path):\n",
    "    \"\"\"\n",
    "    Loads the PDF, splits by Markdown headers, and then by tokens.\n",
    "    \"\"\"\n",
    "    print(f\"Loading {pdf_path}...\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    raw_documents = loader.load()\n",
    "    \n",
    "    # Merge pages into a single string for Markdown splitting\n",
    "    full_text = \"\".join([doc.page_content for doc in raw_documents])\n",
    "    \n",
    "    # Split 1: Logical Split by Headers (Sections/Lectures)\n",
    "    print(\"Splitting by Markdown headers...\")\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Section Title\"),\n",
    "            (\"##\", \"Lecture Title\")\n",
    "        ]\n",
    "    )\n",
    "    md_docs = markdown_splitter.split_text(full_text)\n",
    "    \n",
    "    # Split 2: Token Split (Chunking for Embedding)\n",
    "    print(\"Splitting by Tokens...\")\n",
    "    token_splitter = TokenTextSplitter(\n",
    "        encoding_name=\"cl100k_base\",\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    token_docs = token_splitter.split_documents(md_docs)\n",
    "    \n",
    "    print(f\"Total chunks created: {len(token_docs)}\")\n",
    "    return token_docs\n",
    "\n",
    "# Run the loading function\n",
    "pdf_path = \"data/Introduction_to_Tableau.pdf\"  # Ensure file is in 'data' folder\n",
    "documents = load_and_split_documents(pdf_path)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 3: VECTOR STORE & EMBEDDINGS\n",
    "# ---------------------------------------------------------\n",
    "# Initialize OpenAI Embeddings\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# Create Vector Store (Chroma)\n",
    "# Note: We use a local directory to persist the database\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "print(\"Creating Vector Store (this may take a moment)...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(\"Vector Store created and persisted.\")\n",
    "\n",
    "# Create Retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 5, \"lambda_mult\": 0.8}\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 4: RAG CHAIN CONSTRUCTION\n",
    "# ---------------------------------------------------------\n",
    "# Define the Prompt Template\n",
    "template = \"\"\"\n",
    "You are a helpful Q&A chatbot for the 'Introduction to Tableau' course.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "At the end of your answer, explicitly list the 'Lecture Title' and 'Section Title' \n",
    "from the metadata of the context you used.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize LLM (GPT-4o)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# formatting function to join retrieved docs\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Build the Chain (LCEL)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG Chain initialized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 5: INTERACTIVE CHAT (Streaming)\n",
    "# ---------------------------------------------------------\n",
    "def chat_with_bot(question):\n",
    "    print(f\"\\nQuestion: {question}\\n\")\n",
    "    print(\"Answer: \", end=\"\", flush=True)\n",
    "    \n",
    "    # Stream the response\n",
    "    for chunk in rag_chain.stream(question):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Example Usage\n",
    "chat_with_bot(\"How do I create a calculated field in Tableau?\")\n",
    "chat_with_bot(\"What is the difference between a join and a blend?\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
