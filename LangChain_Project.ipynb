{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e4ab21bb-efd7-426a-b845-9491efaf52e3",
      "metadata": {
        "id": "e4ab21bb-efd7-426a-b845-9491efaf52e3"
      },
      "source": [
        "# Create a Q&A Chatbot with LangChain Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96b4cd1-826e-42d0-914d-166ab7d2fa6b",
      "metadata": {
        "id": "c96b4cd1-826e-42d0-914d-166ab7d2fa6b"
      },
      "source": [
        "### Set the OpenAI API Key as an Environment Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fc2d63d7-172f-4aff-a9b8-495aca6396ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc2d63d7-172f-4aff-a9b8-495aca6396ea",
        "outputId": "20396d3a-d598-4e05-eb7e-fc3eee4a8e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dotenv extension is already loaded. To reload it, use:\n",
            "  %reload_ext dotenv\n",
            "cannot find .env file\n"
          ]
        }
      ],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9Ry7gYo67QI"
      },
      "source": [
        "### Install the Libraries"
      ],
      "id": "A9Ry7gYo67QI"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a6d52e-5f65-4763-982e-e415086f1738",
        "id": "hz6aahAD67QJ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.11)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.9)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.9)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.17.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: chromadb<2.0.0,>=1.3.5 in /usr/local/lib/python3.12/dist-packages (from langchain-chroma) (1.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.40.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.24.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.22.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.51.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.67.3)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.21.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (35.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.11.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.26.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.10)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.60b1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.21.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.7.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community langchain-text-splitters langchain-core langchain-openai langchain-chroma\n",
        "!pip install pypdf python-dotenv"
      ],
      "id": "hz6aahAD67QJ"
    },
    {
      "cell_type": "markdown",
      "id": "816561e8-f742-4347-bc7e-0a21b07d2705",
      "metadata": {
        "id": "816561e8-f742-4347-bc7e-0a21b07d2705"
      },
      "source": [
        "### Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CQtYc9P24NM",
        "outputId": "9b95a352-2f8a-497e-c688-cfbe8fb0464c"
      },
      "id": "3CQtYc9P24NM",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-text-splitters\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.9)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.9-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-1.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.3)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.9)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.2.11-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.17.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting chromadb<2.0.0,>=1.3.5 (from langchain-chroma)\n",
            "  Downloading chromadb-1.5.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting build>=1.0.3 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.40.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.38.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.22.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading pypika-0.51.1-py2.py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.67.3)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.21.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.11.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.26.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.0.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.21.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.3.0)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_openai-1.1.9-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.11-py3-none-any.whl (500 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.1/500.1 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-1.1.0-py3-none-any.whl (12 kB)\n",
            "Downloading chromadb-1.5.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.4.0-py3-none-any.whl (24 kB)\n",
            "Downloading kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypika-0.51.1-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pypika, durationpy, requests, pyproject_hooks, pybase64, opentelemetry-proto, mypy-extensions, marshmallow, bcrypt, backoff, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, build, opentelemetry-semantic-conventions, kubernetes, dataclasses-json, opentelemetry-sdk, langchain-core, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, langchain-classic, chromadb, langchain-community, langchain-chroma\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.38.0\n",
            "    Uninstalling opentelemetry-proto-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.38.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.38.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.38.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.38.0\n",
            "    Uninstalling opentelemetry-api-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.38.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.59b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.59b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.59b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.38.0\n",
            "    Uninstalling opentelemetry-sdk-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.38.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.9\n",
            "    Uninstalling langchain-core-1.2.9:\n",
            "      Successfully uninstalled langchain-core-1.2.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-exporter-otlp-proto-common==1.38.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-proto==1.38.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-sdk~=1.38.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.4.0 chromadb-1.5.0 dataclasses-json-0.6.7 durationpy-0.10 kubernetes-35.0.0 langchain-chroma-1.1.0 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.11 langchain-openai-1.1.9 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 onnxruntime-1.24.1 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pypika-0.51.1 pyproject_hooks-1.2.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Downloading pypdf-6.7.0-py3-none-any.whl (330 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.6/330.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-6.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9db4fc20-609b-4066-900a-3050cb80783a",
      "metadata": {
        "id": "9db4fc20-609b-4066-900a-3050cb80783a"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
        "\n",
        "from langchain_text_splitters import (MarkdownHeaderTextSplitter,\n",
        "                                      TokenTextSplitter)\n",
        "\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.prompts import (PromptTemplate,\n",
        "                                    HumanMessagePromptTemplate,\n",
        "                                    ChatPromptTemplate)\n",
        "from langchain_core.runnables import (RunnablePassthrough,\n",
        "                                      RunnableLambda,\n",
        "                                      chain)\n",
        "\n",
        "from langchain_openai import (ChatOpenAI,\n",
        "                              OpenAIEmbeddings)\n",
        "\n",
        "from langchain_chroma.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa29c72",
      "metadata": {
        "id": "dfa29c72"
      },
      "source": [
        "### Load the Course Transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "78cefcca-f280-42fc-821d-b0cee98bdead",
      "metadata": {
        "id": "78cefcca-f280-42fc-821d-b0cee98bdead"
      },
      "outputs": [],
      "source": [
        "loader_pdf = PyPDFLoader(\"Introduction_to_Tableau.pdf\")\n",
        "docs_list = loader_pdf.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "11df1f5b-f8e4-4086-824c-98ec50bfa758",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11df1f5b-f8e4-4086-824c-98ec50bfa758",
        "outputId": "c33e7baa-244e-430d-87e8-2fbd2c2536ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(docs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b7f31df6-4035-4ca2-906e-319b1cf57de3",
      "metadata": {
        "id": "b7f31df6-4035-4ca2-906e-319b1cf57de3"
      },
      "outputs": [],
      "source": [
        "string_list_concat = \"\".join([i.page_content for i in docs_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f0d2134a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "f0d2134a",
        "outputId": "bb26f13f-2692-4e27-fb75-ceeeb3267158"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Introduction to Tableau \\n## Welcome to Tableau \\nHi, everyone. \\nI'm Ned and I'll be your instructor for this \\ncourse. \\nTableau is an invaluable tool. \\nOne needs to learn on their journey to become a \\nsuccessful business intelligence analyst or \\ndata scientist. \\nThe art of these professions is storytelling \\nusing data to tell stories and convince top \\nmanagement of the right course of action. \\nBy completing this part of the program, you \\nwill know how to create charts and dashboards \\nin tableaux. \\nThis is an essential step on your way to a data \\nscientist role. \\n \\n## Why use Tableau: Make your data make an impact \\nTableau has grown to become one of the most \\npopular business intelligence tools in the \\nentire world. \\nIt is A B I software that allows non technical \\nusers to visualize their data and work with it \\nalmost immediately lowering, \\nknow how barriers dramatically in the past. \\nBusiness analysts needed the help of it \\npersonnel who could assist them in gathering \\nraw data and preprocessing it. \\nOnly then could business analysts start working \\non the visualization of such data? \\nThe advent of Tableau democratized this process \\nand allowed B I analysts to be \\nindependent non-technical people can easily \\nload data into the program and start playing \\nwith it. \\nTableau's forte are meaningful intuitive \\nvisualizations and sometimes that's really \\nvaluable analysts are able to explore their \\ndata right away without spending too much timeon numbers which provide limited insights and \\ninstead focus on data that matters. \\nThis is why we can confidently say that Tableau \\nis an indispensable tool in the arsenal of most \\ncorporate business intelligence analysts, \\ndata analysts and data scientists. \\nMany people are uncertain about the difference \\nbetween Tableau and spreadsheet tools \\nlike Excel. \\nAnd that's a reasonable doubt until we point \\nout they serve different purposes using \\ntableaux doesn't necessarily mean you can \\nforget about Excel and vice versa while Excel \\nis not as powerful or \\nintuitive as tableau. \\nWhen it comes to data visualization, \\ntableau is not optimal when you would like to \\nuse it as a data creation tool. \\nAlthough it has several database management \\nfunctionalities, the program isn't the best \\nsolution when you would like to perform \\nmultiple operations with your data before you \\nstart analyzing it. \\nMoreover, tableau isn't great for multilayered \\ncalculations. \\nIt is able to calculate in its own fields, but \\nit shouldn't be used as a spreadsheet tool for \\nmultilayered calculations such as the \\npreparation of a budget in Excel where tableaux \\nsurpasses the competition is in data \\nvisualizations. \\nIt is a very smart program that allows you to \\nvisualize data in a more powerful way compared \\nto Excel. \\nSo for example, when you work with geographical \\ndata, there is no way Excel could interpret the \\ncells in your spreadsheet as a geographical \\nlocation. \\nOn the other hand, Tableau recognizes that and \\nallows you to visualize such data and see how a \\nvariable is distributed geographically. \\nMoreover, tableaux allows you to combine \\nseveral types of charts and build up meaningfuldashboards that are truly interactive and \\nfacilitate additional analysis. \\nOnce you visualize your data, you can easily \\ndig deeper and explore its granularity, \\nfinding the reason for unusual spikes or \\ninvestigating certain trends. \\nEven novice tableau users would be able to save \\na significant amount of time if they transfer \\ntheir pre designed existing Excel dashboards to \\ntableau uploading new data and \\nupdating visuals is more rapid in Tableau. \\nTherefore, we can agree that a competent \\nanalyst needs both Excel and tableaux. \\nGiven that they serve different purposes. \\nTableau is superior when it comes to visuals \\nand dashboards and Excel is a spreadsheet \\ntool we need in order to perform multilayered \\ncalculations in the same way, \\na combat soldier carries a rifle and a pistol \\nat the same time and uses them under different \\ncircumstances. \\nA business analyst should know how to work with \\nboth Excel and tableaux and apply each of them \\nwhen needed. \\n## Let's download Tableau Public \\nOk, guys, it is time to get started with \\nTableaux. \\nLet's type Tableau public in Google. \\nAs you can see the first result, we have points \\nto Tableau's website at www \\ndot tableau dot com. \\nI'll click on the link and this will direct me \\nto the Tableau public Domain. \\nIt shouldn't be too difficult to download \\nTableau from here if you are wondering why we \\nsearched for Tableau public. \\nThe reason is quite trivial. \\nThis is Tableau's free version if you don't \\nhave a paid subscription for Tableaux. \\nThis is an excellent alternative. \\nYou can practice with most of the program's \\nfunctionalities and you don't have to payTableau's annual fee. \\nSo it is up to you. \\nYou can either use Tableau public for free or \\npay for Tableau's desktop version. \\nBoth options would allow you to follow along. \\nThere are some issues when you want to \\nintegrate Tableau public and programming \\nlanguages like R, Python and SQL to do that, \\nyou'll need Tableau \\ndesktop. \\nBut for now, Tableau public will do just fine \\nand allow us to practice at will all I have to \\ndo here is provide an email address. \\nAnd once I have done that, an exe file will \\ndownload automatically on my computer. \\nLet's open the EC file. \\nThis is the standard installation procedure you \\nwill find when installing any program out there. \\nI have to agree to Tableau's terms and \\nconditions and then click install. \\nOnce the installation starts, I simply have to \\nwait. \\nAnd here we are, Tableau is installed on my PC. \\nWe are ready to start our journey. \\n \\n## Connecting data in Tableau \\nRight. Great. \\nHere is our freshly installed version of \\nTableaux. \\nI am sure you are anxious to create some \\nfascinating visualizations. \\nSo let's get started. \\nFirst off, we need to learn how to connect \\nTableau to the data source we will be working \\nwith. \\nThere are two options, we can either create a \\nconnection to a file or a server. \\nOf course, \\nwe'll choose one of the two depending on where \\nthe data is. \\nLet's connect Tableau to a Microsoft Excel file \\nin general.Every time we use a source file in one of the \\nlectures, you will be able to find it in the \\nsupplemental resources section. \\nJust open your course curriculum and download \\nthe available files for that lesson. \\nSee, OK, great. \\nI'll select the file called GDP data and under \\nconnections. \\nI can now see that Tableau opened the file. \\nOur source has three sheets, data, metadata, \\ncountries and \\nmetadata indicators. \\nWhat we usually have to do is choose the \\nworksheet we'll need and drag into the upper \\npart of the screen where drag sheets here is \\nwritten. \\nOnce we do that tableaux is going to activate \\nthe sheet we selected and provide us with a \\npreview of the data we have inside the first \\ntwo rows of the sheet are empty. \\nAnd hence, we see all of these null values \\ntableaux is really smart \\nand can often help us with similar issues. \\nAs you can see here, the program suggests using \\nits data interpreter functionality \\nto clean the data. \\nAll right, let's do that. \\nAnd voila the first two rows containing no \\nvalues disappeared. \\nThat's awesome. \\nIn our next video, we'll open our first tableau \\nworksheet and I'll be happy to introduce you to \\nits structure. \\nThis will do for now. \\nThanks for watching. \\n \\n## Exploring Tableau's interface \\nSo we've already connected our file to tableaux. \\nNow, in this lesson, we'll be creating our \\nfirst sheet. \\nIt's really easy to do and resembles how we \\ncreate a sheet in Excel or pretty muchevery other spreadsheet software. \\nAll I have to do is click here and a new sheet \\nwill be created, right? \\nThis is what a Tableau sheet looks like. \\nWe can have as many of them as we want. \\nI can simply click on this little icon at the \\nbottom and a new worksheet is added. \\nThe other two icons which are next to it are \\nfor creating a new dashboard and a new \\nstory. \\nWe'll deal with dashboards further in the \\ncourse. \\nSo we won't use these buttons for now. \\nOK. \\nLet's give some structure to what you are \\nseeing here. \\nIf this software is new to you, \\nthings can be a bit confusing. \\nSo it will be best if we spend a few minutes. \\nThe remainder of this lesson talking you \\nthrough Tableau's interface. \\nFirst off, we have 10 different tabs on \\nTableau's default ribbon. \\nThese are file data worksheet dashboard, \\nstory analysis map format window \\nand help. \\nLet's quickly go through each of them. \\nAs with most programs, the file tab contains \\ncertain functionalities related to opening, \\nclosing and saving files if you would like to, \\nyou can also exit tableau from here. \\nBut why would you want to do that data? \\nOn the other hand is where you will find \\nfunctionalities related to the data source you \\nare using here, \\nyou can add a new data connection, replace an \\nexisting one or simply edit the data \\nsource of the worksheet you are working with. \\nNext, we have the worksheet tab. \\nIt can be helpful when we want to create a new \\nworksheet hide or show a charts, \\ntitle caption summary and so on. \\nI am sure you noticed that we already created anew sheet with the little icon we have at the \\nbottom left corner of the sheet and we can do \\nthe same thing from the worksheet tab as well. \\nSuch repetition is common for most programs, \\nfunctionalities available in the ribbon \\ncan be accessed in other ways too. \\nIn fact, I rarely use the ribbon \\nfunctionalities, but it is good to have an \\noverview and be aware that they are there. \\nOK? \\nNext, we have the dashboard and story tabs. \\nAs I said, we'll learn more about dashboards \\nand stories later on. \\nIn the course, the analysis tab is where you \\ncan tweak your visualization in terms of \\nlabels, show figures as a percentage of the \\ntotal add trend lines, \\nlegends filters and more. \\nWe'll explore many of these options later in \\nthe course for now, \\nyou can remember that here, we have some \\ninteresting functionalities related to the way \\nwe perform our analysis. \\nAnd some of the tools we'll incorporate in it \\nmap is a tab that is helpful when we use \\nTableau's geographic visualization capabilities. \\nPretty soon. \\nYou will see that this is one of the most \\npowerful and impressive tableau features. \\nOf course, format can help us adjust the way \\nour visualization appears from here. \\nWe can modify its font, font size, axis, \\nbackgrounds, \\nlabels, size and so much more. \\nThat's another tab containing plenty of useful \\nfunctionalities. \\nWe'll explore later windows and help are two of \\nthe standard tabs we find in most \\nprograms. \\nSo I am not going to spend much time on them \\nalso because we are not going to use them \\nthroughout the course. \\nHowever, one thing we should mention is thatTableau public has a nice and open community of \\nusers who will be able to help you and whose \\nwork you can look at if needed, \\nall users of Tableau public who save their work, \\nmake it publicly available. \\nTherefore, this can be a useful place where you \\ncan search for a given issue you need help with \\nand see what comes up. \\nSo if I click on community and search for \\ngeography, I'll be able to see the \\nwork other users have saved previously, right? \\nThis is Tableau's ribbon \\nbelow the ribbon, we have several buttons that \\ncan be quite helpful. \\nThe show start page button takes us to the \\nscreen we saw previously when we connected \\ntableaux and our GDP data Excel file to get \\nback to the sheet that was created earlier. \\nI'll click here. \\nI'm sure you know how to work with undo and \\nredo. \\nSo if I were to drag one of the fields here, I \\ncan go back and undo this section with \\nundo. \\nOf course, see undone. \\nMost of the typical windows shortcuts can be \\nused here as well as you probably know. \\nThe shortcut for undo is control Z. \\nOn the right, we have other useful buttons such \\nas save, \\nallowing you to save the progress of your work. \\nQuite intuitively. \\nNew data source opens the connect functionality \\nwe saw earlier. \\nThe other buttons we have here are new \\nworksheet, clears, \\nsheet swap rows and columns, sort and so on. \\nWe'll explore many of these throughout the \\ncourse for now, \\nit would be best if you simply gain an idea how \\nvarious objects are positioned within Tableau's \\ninterface. OK. \\nOn the left side of Tableau's screen,we have two pas data and analytics. \\nThe data pane is quite important. \\nIt shows us what data we've loaded and then \\nTableau classifies the data into two \\ntypes dimensions and measures to put it \\nslightly differently. \\nThis is a distinction between categorical and \\nnumerical data. \\nThe data in the dimensions field cannot be \\naggregated. \\nIt is qualitative in nature. \\nQuite the opposite measures can be aggregated \\nand are quantitative in nature. \\nIn the next few lessons, we'll learn how to \\nwork with these fields. \\nBut for now, it would be nice if I just show \\nyou that we can drag dimensions and measures \\ninto the work area and use them to create our \\nvisualizations there. \\nThe work area is where we'll create our \\nvisualizations, dashboards and stories and \\nthis is one way to create a chart. \\nI am sure you noticed that the columns and rows, \\npart of the sheet started showing us the \\nvariables we've added to the workspace area. \\nWe'll explore this part of the interface in a \\nseparate video in a few lessons. \\nOK. Perfect. \\nWhat else do we have the show me button on the \\nright, which allows us to adjust the type of \\nvisualization we use. \\nIt is a very cool feature because tableau tells \\nus what types of visualizations we can \\nchoose from as not all charts will be available \\ndepending on the data we have chosen to work \\nwith. \\nOnce we decide we would like to switch to a \\ndifferent chart, all we need to do is select \\nthe respective type of chart and tableau makes \\nthe adjustment for us neat, right? \\nAnd finally, here in the middle, we have three \\nimportant sections, \\npages, filters and marks the pages shelf.Lets you \\nbreak a view into a series of pages. \\nSo you can better analyze how a specific field \\naffects the rest of the data in a view we'll \\nuse the filter shelf when working with \\nfilters and filtering our data. \\nThe marks shelf on the other hand contains \\nfunctionalities related to coloring size \\nlabels and so on. \\nThis lesson was a quick overview of Tableau's \\ninterface. \\nI am sure now you have a better idea of what \\nyou see in front of you. \\nWhen you open the program in the lessons to \\ncome, we'll continue to explore Tableau's \\nfunctionalities and you'll learn a ton about \\neach of the buttons we mentioned here as of now, \\nthis will do. \\nThanks for watching. \\n## Let's create our first chart in Tableau! \\nAll right, excellent. \\nIt is time to continue our adventure in \\nTableaux. \\nIn this lesson, we'll create our first \\nvisualization and it is going to be awesome \\nready. \\nLet's get right into it. \\nThen as you can see the workspace area is empty \\nright now, \\nwe've already loaded the GDP data file and we \\ncan see that here. \\nActually, let's open the GDP data XL file for a \\nsecond. \\nI want to make sure you are familiar with its \\nstructure here. \\nIt is we have a few blank rows but tableau took \\ncare of them. \\nThen we have a column with country names, a \\ncolumn indicating that this is \\nGDP data and several columns with GDP figures \\nfor each of these \\ncountries.And this is the data sheet we are using right \\nnow. Perfect. \\nLet's go back to tableaux. \\nThe way data is organized here is rather \\ninteresting. \\nOur attention should be focused on the \\ndimensions and measures part of the screen. \\nFirst off, we notice that tableau has been very \\nsmart and managed to organize our \\ndata. \\nCategorical variables are right here under \\ndimensions. \\nWhile numerical data such as the country's \\nactual GDP is under measures dimensions have \\nbeen colored in blue \\nand measures are in green. OK. \\nAnother important remark we have to make is \\nthat some of the fields we see here are in \\nitalics and others aren't the distinction \\nbetween the two is that tableau generates \\ncertain fields based on the data. \\nIt finds when tableau generates its own fields \\nsuch as the measure names field we see here. \\nThese are fields that are not contained in \\nour original data source, But tableaux deems \\nthat these can be useful and creates \\nthem for us. \\nThe same thing is true for latitude, \\nlongitude, number of records and measure values \\nwe see in green \\nunder measures. \\nThe rest of the fields written without italics \\nare ones we saw in the XL file. \\nWe loaded country name, indicator name and the \\nyears from 2002 to \\n2016 where we have country's GDP figures. Good. \\nAnother important detail I would like to \\nmention is that tableaux adds an icon right \\nnext to each of the fields we have under \\ndimensions and measures. \\nThis is what allows us to understand how \\ntableau reads the data. \\nThe first field under dimensions is countryname and its icon is the \\nglobe. \\nTableau recognizes that this field is related \\nto actual countries and it is ready to help us \\nout when we need to visualize such data. \\nIf I click on the icon, I'll be able to see \\nthat this is a string and that its \\ngeographic role is of country region as it \\nshould be. \\nAt the same time, the tiny ABC icon of the \\nindicator name field shows us that \\nthis is a text value. \\nAnd in fact, when I click on it, I can see that \\nthis is a string but different to what we have \\nfor the country name field. \\nThe geographic role of indicator name is none. \\nThat's because this is purely a text value. \\nWhat about the year measures we have below? \\nWell, these are numerical values, right? \\nTherefore, it comes as no surprise that when we \\nclick on their icon, \\ndesignating numerical values, we will see these \\nare numbers. \\nOK? Perfect. \\nLet's do the following. \\nI'll drag the country name field into the \\nworkspace area and boom \\nTableau created a world map that shows us the \\nlocation of each of the countries we have in \\nour data source. \\nIt is quite interesting to see that the field \\nwe see under columns and rows isn't country \\nname but are artificially generated longitude \\nand latitude fields. \\nAt first, it may seem strange but then when you \\nthink about it, \\nit is intuitive. \\nTableau understands country name is a \\ngeographical field. \\nThis is why it will do much more than simply \\ncreate a row or a column containing a list of \\nthe country we have in the Excel file. \\nNo, the program is smarter than that.It reads the country names and then creates the \\ntwo fields, \\nlongitude and latitude in order to map each \\ncountry geographically and hence the \\nbeautiful map we have here. \\nNow, if I drag the year 2016 in the map, \\ntableau will update the \\nchart adding the 2016 GDP of each country. \\nWe can see that happen. \\nIf we hover above each of the dots we have \\nrepresenting the countries on our map. \\nSee the US GDP for 2016 was more than $18 \\ntrillion while Canada's GDP was around $1.5 \\ntrillion. \\nOK. Perfect. \\nEverything's good. \\nOur first visualization and Tableau is almost \\nready. \\nOne last finishing touch I would like to add is \\nto enlarge the bubbles a bit indicating how \\nlarge a country's GDP is to \\ndo that. \\nI can work with the newly appeared sum 2016 pan \\non the right side of the screen, I'll click on \\nits tiny arrow and we'll select \\nedit sizes, the edit sizes, dialog box allows \\nme to enlarge the bubbles we see in \\nthe visualization. \\nI think this will do let's click apply. \\nAnd as you see the bubbles in the visualization \\nincreased. \\nThis makes it a bit easier to compare the GDP \\nof different countries. \\nThe final touch will be to edit the name of \\nthis visualization. \\nI'll double click here and simply type a title. \\nAnything is better than sheet one. \\nThat's why I'll simply type GDP per country \\ncomparison. \\nAnd here we are, that's our first visualization \\nin Tableau and we are just getting \\nstarted# Tableau Functionalities \\n## Creating a table \\nOk, perfect. \\nIn this lesson, we'll continue exploring some \\nof Tableau's main features in particular, we'll \\nlearn how to create a table with data \\nand add some custom fields. \\nThe table we will create is going to be a \\npretty simple one, \\nproviding a monthly and yearly breakdown of a \\ncompany's sales. \\nAs you can see, our original data source \\ncontains a column called period. \\nThis is where we have both yearly and monthly \\ndata. \\nThe first four characters designate the year \\nwhen a sale was made and then the last two \\ncontain information about the month when the \\nsale occurred. \\nWhat I would like to do is split this \\ninformation into two separate custom fields, \\nyear and month. \\nThe way to do that is to go to the analysis tab \\nand create a calculated field, \\nright? \\nOnce this dialog box opens, I'll type the name \\nof the field I am creating which is year. \\nThen I'll use the left function in order to \\ntake the four leftmost symbols of \\nthe period field. \\nThis is where we have the year when the sale \\noccurred. \\nLeft is a function. \\nMost of you are probably familiar with in \\nTableau. \\nIt works in the exact same way as it does. \\nIn Excel. \\nFor example, in our next lesson, we'll pay \\nextra attention to the different types of \\noperations you can do to create custom fields. \\nOK? \\nTableau recognizes we are writing the leftfunction and it helps us with autocomplete \\nsuggestions. \\nThe left function needs two arguments from us a \\nstring which in this case \\nis the period field we have in our source sheet. \\nIt is important to make sure that the period \\nfield, data type is a string otherwise \\ntableau will show an error. \\nSo I'll type period. \\nAnd as I do that, tableau manages to recognize \\nI'm referring to the period field and \\nallows me to select it right away. \\nThe second component of the formula is the \\nnumber of characters we would like to extract, \\nwe'll need four characters and that's what I'll \\nwrite here, \\nclose the brackets and our new field is ready. \\nIf the period field was not of the string type, \\nwe would have had problems because \\nleft is a function that requires us to use \\nstrings, I'll change the data type of the \\nperiod field. \\nAnd as soon as I do tableaux shows us a warning \\nsign next to the newly generated field year. \\nAnd it doesn't allow us to drag this field into \\nthe workspace area. \\nBasically, we can't use it. OK. \\nI'll change the type of data of the period \\nfield back to string and the issue will be \\nresolved. \\nNow, I can easily drag the year field into the \\nworkspace area. \\nSee, perfect. \\nThe other field I would like to create is month. \\nAnd in order to do that, \\nI'll use the right function again, we'll need \\nto go to analysis and create a calculated \\nfield. \\nFirst, we'll assign it with a name months and \\nthen I'll type in the right function following \\nthe exact same procedure as before \\nthe string we'll need is the same period. \\nand the number of characters we'll need is two,given that months are the two \\nrightmost characters within the period field. \\nExcellent. \\nNow that we have our second field months, \\nlet's add it right next to years in the \\nworkspace area. \\nI can do that in two ways. \\nI can either drag the field into the workspace \\narea and place it right next to the year's \\ninformation or alternatively drag the month \\nfield right next to the year's field in the \\nrows. \\nPart of the screen, the output is the same. \\nNow, we should create a new calculated field \\nand name it number of \\nrecords in the box below. \\nWe will just type the number one and press. \\nOK? \\nThis field represents a simple count of the \\nrows we have in our source data. \\nOK? Great. \\nWe've managed to create a nice table that \\ngroups all 12 months of 2016 and \\nall 12 months of 2017. \\nI'll simply insert the number of records field \\nwe just created and voil. \\nThis is a nice table that shows us the \\nbreakdown of the company's total number of \\nsales for each month in 2016 and 2017. Awesome. \\nRight. \\n## Creating custom fields \\nWe already know how to create custom fields. \\nWe did it two times in our previous lesson, \\ncreating the years and months fields. \\nIn this lesson, \\nwe'll spend some time describing some of the \\nother ways you can transform your source data \\nand create custom fields. \\nRemember, we shouldn't go too far with these as \\nTableau's main purpose is visualization and not \\ndata creation or modeling. \\nHowever, sometimes it can be really handy toperform certain manipulations once we've loaded \\nour data into tableaux and we need a certain \\ntype of analysis. \\nOK. \\nHere we go. \\nThe typical Tableau operators you'll need to \\nremember are plus for addition, \\nminus for subtraction star for multiplication \\nforward slash for division \\nand carat for elevation alongside these, you'll \\nprobably need comparison operators \\nsuch as equal, higher, then lower than higher \\nor \\nequal and different. \\nThen the logical functions available in Tableau \\nare like the ones we have in Excel and or and \\nnot a lot of the \\nfunctions and symbols used in Excel can be used \\nwhen creating a calculated field. \\nSo for example, some of the most commonly used \\nfunctions are some for some \\naverage for average min and max allowing you to \\nfind the minimum and maximum \\nvalues within a range. \\nAnd A BS returning the absolute value of a \\nnumber. \\nAnd we already saw the text functions left and \\nright. \\nThey allow us to extract a leftmost and a right. \\nMost number of characters within a string we've \\nspecified besides left and right. \\nWe can also use the typical text functions \\navailable in Excel Mid providing us characters \\nthat are in the middle of a text string, upper \\nand lower allowing us to either convert it to \\nall upper case characters or convert it to all \\nlower case characters. \\nThis was a nice recap of the types of operators \\nwe can use in order to create custom fields in \\ntableaux. \\nFor more information on this topic, \\nwe'll add a downloadable file attached to thislesson. \\nThanks for watching. \\n## Creating a custom field and adding calculations to a table \\nRight. \\nSo we are ready to go back to Tableaux and \\nperform a few additional operations with the \\ntable we created earlier right now. \\nIt shows us the number of units sold by the \\nfirm in each month of 2016 and 2017. \\nLet's change this measure. \\nWhat I would like it to show us is the revenue \\nthe company generated during each of these \\nperiods. \\nHow can I do that? \\nWell, it's fairly easy. \\nOur source data contains information about \\nprice and tableaux counted. \\nThe number of units sold each row shows us a \\nsingle car sale, right? \\nTherefore, if we multiply the price field and \\nthe auto generated number of records \\nfield, we would obtain revenues. \\nDo you agree? \\nOk, good. \\nLet's do that. \\nWe already know how to create a calculated \\nfield. \\nI'll name it revenue and we'll take advantage \\nof Tableau's autocomplete suggestions by \\nmultiplying price and number of records. \\nSee as we said in our previous lesson, we can \\nuse the star operator to carry out a \\nmultiplication. \\nOne very useful feature you have probably \\nnoticed is that at the bottom of the screen \\ntableau tells us whether the calculation we've \\nentered is a valid one or not. \\nRight now, my calculation is valid if I remove \\na few symbols tableau would indicate \\nthat the calculation contains errors. \\nThis is a good guiding light when we create a \\ncalculation, right.So this is our revenue field, \\nwe can easily substitute the number of records \\ndata in the table with it. \\nAll I have to do is drag the revenue field and \\nposition it over the number of records data \\ntableau replaces the two fields. Perfect. \\nAn important metric contained in our source \\ndata is gross profit. \\nBy definition, revenue minus cogs equals gross \\nprofit. \\nCurrently, we have revenue and gross profit. \\nLet's calculate cogs as the difference between \\nthe two. \\nThat's easy to do. \\nAll we have to do is use the minus operator. \\nNice. \\nLet's order our table in the following way. \\nFirst we'll have revenue then cogs and finally \\ngross profit. \\nI can do that by dragging and dropping the \\nthree fields within the table. \\nPlease note that their values appear in the \\nmeasure values card on the left side of the \\nworkspace area, we can change their order \\neither from here or directly inside the table. \\nIt's up to you. \\nOne more thing you have probably noticed the \\nmeasure names field which appeared in the \\ncolumns section. \\nThis is an auto generated field tableau uses in \\norder to form our table and separate the \\nnames of different measures. \\nIf we were to remove it from the column section, \\nthe table will lose its shape and all three \\nmeasures will be put together. \\nLet's press control and Z and undo this action. \\nOK. Excellent. \\nIn our next lesson, we'll learn how to add \\ntotals and subtotals to our tables in tableaux. \\nThis will do for now. \\nThanks for watching.## Adding totals and subtotals \\nMost executives and by most, I mean, all of \\nthem prefer receiving tables that contain \\ntotals and subtotals. \\nThis makes it easier for them and helps them \\ndigest information in a faster way. \\nIn this lesson, we will learn how to add totals \\nand subtotals to our tableau tables. \\nThat's nice because the table we have been \\nworking on in the last few videos doesn't \\ncontain totals for 2016 and 2017. \\nWe'll add them in this video. \\nThat's fairly easy to do. \\nI'll go to analysis then totals and we'll \\nselect show column, \\ngrand totals. \\nThe totals we just added are for the entire \\nperiod 2016 and 2017. \\nThat's not really useful. \\nIs it whenever a person is interested in a \\ncompany's sales or gross profit, they want to \\nknow how much it made in a specific year and \\nwhether it performed better than the year \\nbefore a company will also want to know how its \\nyear's sales compare to other companies. \\nSo I'll go to analysis totals and unclick the \\nshow column, grand totals to remove the total. \\nWe just added what I can do differently. \\nThe second time around is opt for add all \\nsubtotals. \\nAnd this will give me the total figures for \\n2016 and 2017 \\nseparately. \\nQuite nice. \\nRight now, we can read the table easily the \\nfictitious numbers we see here, \\nhelp us compare 2016 and 2017 and give us a \\ngood idea of what the \\nactual sales were for that period. \\nIn our next lesson, we'll add percentage, gross \\nmargin to our table. \\nThanks for watching.## Adding a custom calculation \\nOk, excellent. \\nWe're doing good. \\nWe've seen quite a few interesting tableau \\ntools so far and we'll continue to do so during \\nthis lesson as well. \\nOur table is almost ready. \\nWe have revenue cogs and gross profit. \\nNow that I think about it, one thing we should \\nprobably add is a gross margin calculation \\nright next to the gross profit figures. \\nGross margin is useful because it allows us to \\nsee what portion of revenues were converted \\ninto gross profit once we have considered the \\ncost of goods sold. \\nRight. \\nLet's add a new calculated field. \\nI'll name it GM percent. \\nAll we have to do is divide gross profits by \\nrevenue, right? \\nAnd we already know how to do that. Ok. \\nHere we are. \\nWe've calculated a new field. \\nLet's add it to the table. \\nI'll insert it in the measure values card there. \\nI've added the new field right next to gross \\nprofit. \\nBut it looks strange, doesn't it? \\nIf we divide gross profit by revenues, we would \\nusually expect a number in the region of 10, \\n2030 or maybe 50%. \\nCertainly not 1000. \\nWhat is going on here when I divide 71 million \\nby 244 million, \\nwhich is what we have in January. \\nI obtain 29%. \\nApproximately. \\nThere are two possible explanations. \\nEither tableau miscalculated, the simple \\ndivision we asked it to perform or our formula \\nis not 100%. OK.It's most likely us and not the computer, right. \\nI'll take out the GM percent field from the \\nmeasure values box and we'll edit the \\ncalculated field from here. \\nWhat we forgot to do is type sum around the two \\nvariables. \\nIf we don't sum the variables, we are not \\ndividing their total figures for each month. \\nLet's adjust our calculated field in this way \\nand see what happens. \\nOK? \\nThis is a column with numbers that look like \\nzeros, but perhaps these are percentage values. \\nLet's change the way the GM percent \\ncolumn is displayed to do that. \\nI'll simply click on the GM percent variable in \\nthe measure values card and select the format \\noption. \\nWe have quite a few options available here. \\nSo I'll simply select a percentage format with \\none decimal place. \\nVoila. \\nOur table is ready in our next lesson. \\nWe'll add a filter that would allow us to \\nchoose whether to see both 2016 and 2017 \\nvalues or just one at a time. \\nSee you there. \\n \\n## Inserting a filter \\nOne of the most interesting options available \\nin tableaux is adding a filter to the \\nvisualization you are working on in this lesson, \\nwe'll learn how to do that. \\nOf course, we'll add a filter to our table from \\na user standpoint. \\nThe only field which makes sense to be filtered \\nin this table is the year field. \\nA person could be interested in seeing numbers \\nfor 2016 or 2017 \\nonly. \\nFor example. \\nSo what I'll do is select the analysis tab andthen select filters, \\nchoosing the year field. \\nAs we had already decided, \\nwe would like to create a filter for years. \\nAnd as we do that, a filter appears on the \\nright side of our workspace area. \\nNow, we can easily hide 2017. \\nFor example, I'll simply untick its \\nvalue and everything related to 2017 disappears \\nfrom the sheet \\npretty cool. \\nRight? \\nOf course, we can do the same with 2016. \\nI'll select 2017 and unti 2016. \\nAnd here we are. \\nWhen we click on the tiny arrow which is in the \\nupper right corner of the filter pane, \\nwe find plenty of options that allow us to \\nadjust the filter we've created. \\nFor example, we can change its appearance to \\nsingle value list, \\nrepresenting radio buttons have a filter as a \\ndrop down menu, \\na multiple values list and so on and so forth. \\nWe can easily change the filters formatting by \\nselecting format filters. \\nOr alternatively, we change the filters title \\nby clicking on the edit title button. \\nWhat else can we do? \\nOh, yes. \\nWe can choose whether to apply the filter to \\nthe current working sheet only or to all \\nworksheets in the tableau file we are working \\nwith. \\nAnd that's really useful when working with \\nseveral interrelated sheets. OK. \\nThis was our short introduction to filters in \\ntableaux. \\nThis will do for now. \\nThanks for watching.## Working with joins in Tableau \\nOne of the most important aspects of your work \\nin tableaux is the data source you are using to \\nperform analysis quite often, the data will be \\nstored in multiple locations and hence, \\nyou will have to deal with a number of data \\nsources which live in different environments. \\nNevertheless, you are going to want to use all \\nof the data available to you and run analysis \\non everything together. \\nThe way we merge multiple data sources is by \\nusing joins for those of you who have already \\nfollowed our program and especially our SQL \\nvideos you'll be familiar with what follows in \\nthis video. \\nSo feel free to skip or continue watching as a \\nrefresher for the rest. \\nPlease follow along when we want to perform \\ncross data table joins. \\nWe want to combine two or more data tables to \\ncreate a unique database. \\nHow do we join separate data tables? \\nWell, there are a few ways to do that. \\nWe can create an inner, outer left or a right \\njoint. \\nLet's open an Excel file to demonstrate a bit \\nbetter what each type of joint represents. \\nHere, we have two very simple tables. \\nThe first one shows us the age of three \\nbasketball players and the second one shows us \\nthe salary of basketball players. \\nPlease note that the two tables are different \\ndue to their last rows. \\nWe have lebron James in the first one and Kyrie \\nIrving in the second. \\nOk, let's say we would like to run some \\nanalysis and use the data available in both \\ntables. \\nTherefore, as described earlier, we have to use \\njoints. \\nBut how do we do that? \\nWe can easily see that the two tables have one \\ncolumn in common.The basketball player column, this column will \\nserve as a key. \\nWhen we put together the information from both \\ntables, a left join would mean that the left \\ncolumn of the first table will lead the way we \\nwill use it to create a table containing \\nage and salary information about the three \\nplayers we see here. \\nWhenever we find one of these players to the \\nright, we'll add their salary in the new table. \\nAs you can see here if their name is not \\npresent to the right, \\nwhich is the case with lebron james' salary, we \\nwill have a null value in the table. \\nIf a player's name is not present in the left \\ncolumn of the first table, \\nwe will not include any information about them \\nas this is a left join and any rows \\nwhich are not present in the key field of the \\nleft table are omitted in the new table. \\nA right join functions. \\nIn the same way. \\nHowever, this time, the left column of the \\nsecond table leads the way Kyrie \\nIrving replaces lebron James who is not present \\nin the left table. \\nHence, the only missing value would be Kyrie \\nIrving's age. \\nGiven that the only information we have about \\nhim is in the right table. \\nThe case when we are interested in the \\nintersection of the two tables only is called \\nan inner join. \\nThis is when we create a table that contains \\nrows where we have an exact match between the \\nkey fields we are joining the two tables with \\nin our case, \\nbasketball player. \\nThis time, the newly created table contains two \\nrows, only, \\nboth tables contain information about these \\nplayers. \\nHence, this is an inner join.An outer join would be the opposite case we add \\nall rows of the two tables regardless of \\nwhether there is a match in the key field we \\nare linking with. \\nWhen there isn't, we would have null values, \\nwhich is the case with both lebron James and \\nKyrie Irving. \\nHere, these are the main principles you need to \\nunderstand when deciding whether to create a \\nleft, right, \\ninner or outer join in tableaux depending on \\nyour needs. \\nAnd on the specific case you are working on, \\nyou will be able to apply one of these \\nstructures and join your data. \\n \\n# The Tableau Exercise \\n## Introduction to the exercise \\nHello and welcome back. \\nNow that we are nearly finished with our \\nintroduction to Tableau. \\nIt is time to start creating great looking \\ncharts and use them to build a complete \\ndashboard. \\nThis is way more exciting than getting \\nacquainted with Tableau's interface. \\nIsn't it to do that? \\nWe'll solve a complete real life exercise and \\neach lesson will build upon the previous one. \\nSounds great. Right. \\nAll right. \\nThen let's get started. \\nHere's the Excel data we'll use. \\nIt was provided by a company that has produced \\nseveral audio books and has been selling them \\nat an online marketplace. \\nOne of the main components of that marketplace \\nis reviews. \\nSo we have two files, one about sales and \\nanother one containing information aboutreviews. \\nCustomers left for each audio book, \\nboth files contain the date when a purchase or \\na review occurred. \\nIt will be great if we manage to produce a \\ntable that takes advantage of both types of \\ndata we have when a person bought an audiobook \\nand when and with which rating a \\nperson left a review. \\nIf we manage to do that, we'll be able to \\ncreate several different charts in Tableau that \\nwould allow us to learn if the number of \\nreviews the company receives has been growing. \\nHow did the average review score change over \\ntime? \\nWhat is the percentage breakdown between 10 \\nstar, nine star, \\neight star and other types of reviews? \\nWhat percentage of people acquiring an \\naudiobook? \\nLeave a review, visualize the correlation \\nbetween audiobook sales and number of \\nreviews or perhaps visualize the correlation \\nbetween average review score and sales \\nin the lessons to come. \\nYou'll see how to do all of that. \\nStay tuned and thanks for watching. \\n## Let's create a dashboard - Visualizing the three charts we want to create \\nAll right, very good. \\nLet's take a look at the following picture. \\nThis is where we want to get by the end of our \\nexercise. \\nOur goal is to create a dashboard containing \\nthree charts, \\na chart showing us the number of reviews with a \\nsecond axis measuring the monthly average score. \\nThen we would like to create a pie chart \\nshowing us the percentage of reviews each \\naudiobook obtained. \\nFor example, 50% audiobook, \\n1 25% audiobook, 2 10% audiobook three and so \\non.And finally, we would like to create a chart \\nthat gives us information about the ratio \\nbetween reviews left and the number of \\naudiobook purchases. \\nSuch a visualization would help us understand \\nwhat portion of people buying an audiobook, \\nlisten to it and then leave a review. Ok. \\nThese three charts will be the foundation of \\nthe dashboard we will create later on. \\nAnd I've added a note on the side showing us \\nthat once the dashboard is ready, \\nwe will be able to look at the aggregate data \\nor use a filter to monitor the performance of \\nindividual audio books. \\nSounds exciting, right? \\nAs a side note here, I would like to add that \\nin general, \\nit is a good practice to sit down and design \\nyour dashboards before you start working in \\ntableaux. \\nThis allows you to have a predefined idea of \\nwhat you would like to achieve and to check \\nwhether you are able to do that at the end. \\nMoreover, and what is probably most important, \\nthis allows you to think what visualizations \\nmake sense from a business perspective. \\nOK, great. \\nLet's get right into it in our next lesson. \\n## Using Joins in Tableau \\nAs usual. \\nThe first thing we need to do when starting a \\nnew project is load our data. \\nOur two source files are audiobook reviews and \\naudiobook sales. \\nLet's connect them to Tableau. \\nHere's the audio book reviews file in the same \\nfolder. \\nWe also have the audiobook sales file. \\nWe'll need both. \\nSo I'll click on add and we'll load the other \\nfiles too in order to be able to use the \\ninformation of both tables at the same time,we'll have to combine them somehow to do that. \\nWe must double click at the audiobook \\nsales gray button that is in front of us. \\nThen we can drag the audiobook reviews \\ntable from the sheets field on the left. \\nWe've just created the join. \\nWe need excellent what we want to obtain by \\ndoing that is a unique table containing \\ninformation about all transactions for all \\naudio books and the respective reviews left by \\nclients whenever they chose to do so, \\nthe transaction ID column is the perfect link \\nbetween the two files as it is available \\nin both. \\nAnd it could serve as a common field based on \\nwhich we could link the two tables together. \\nSo one of the main aspects we'll explore in \\nthis lesson is how to create a connection \\nbetween two tables in tableaux. \\nPlease remember that we will distinguish the \\nterms data connection and table connection. \\nTable connection is performed by \\nfunctionalities like joining or blending. \\nIt refers to combining data from two or more \\ndata sources. \\nData connection instead represents a single \\ndata source connection between Tableau \\nand a data source such as an Excel workbook or \\nan SQL database. \\nWhen we imported the second file Tableau did \\nsome work for us in the background and created \\na connection between the two files. \\nThe symbol you see here is an indication we've \\ncreated an inner join. \\nTechnically speaking, when creating a join, \\nTableau sends a query to the database, \\nthe joint is implemented on the relevant tables \\nat the database level and the output of the \\noperation is brought back to Tableau where it \\nis ready to be used for analysis. \\nAnd inner join means that the two tables we've \\nadded have a field in common and we \\ncan combine them using that field.Let me hover my mouse over the symbol tableau \\nindicates that it has created an inner \\njoin using the parameter audiobook name. \\nWe don't want that. \\nWe want to link the two tables according to the \\ntransaction id parameter. \\nAs our analysis will be focused on user sales \\nand reviews. \\nSo I'll click on the inner join symbol and \\nwe'll open the join menu first \\noff. \\nLet me substitute the field we use. \\nIn order to create a connection between the two \\ntables, I would like to create a connection \\nusing the transaction ID field. \\nAnd here we are, here's a preview of the table \\nwe've created through an inner join and \\ntransaction ID as the primary key as shown in \\nthe diagram. \\nWhen we create an interj join between the two \\ntables, we consider their intersection the \\nsituation where the primary key is found in \\nboth tables. \\nTo give you an example, if a person who has a \\ngiven transaction ID purchased a course \\nbut did not leave a review, then they won't be \\nincluded in this table. \\nAnd inner join would require users who have \\npurchased a course to have left a rating \\nand both the date of purchase and the date when \\nthe rating was posted to be known. \\nBasically, it contains only the rows in which \\nwe have a transaction ID, \\na date of purchase, a date of review, a review \\nrating and information regarding which was the \\naudio book that was purchased and rated. \\nFor example, all the cases when a person bought \\nan audio book but did not rate, \\nit are not considered. \\nDo you think this information is important? \\nDo we want to be able to understand how reviews \\nimpacted sales and whether we can see a \\npattern in total purchases with respect toreviews? \\nOf course, we'll need this information. \\nAnd if we use an inner join, we are not going \\nto have it. \\nTherefore, we'll need a different type of join. \\nOne that includes the information about \\npurchases and people who did not rate an audio \\nbook. \\nSo looking at the tiny diagram we have here, \\nI am going to select a left join. \\nGiven that the audiobook sales file is on the \\nleft side. \\nWe want to have a table that contains \\ninformation regarding audiobook purchases, \\nall of the audiobook purchases. \\nAnd the case is when people who bought these \\nbooks provided a rating and a left join is more \\nsuitable than an inner join in \\nthis case. \\nOk, great. \\nIn our next lesson, we'll make a check to see \\nwhether the data we've connected to Tableau is \\ncorrect. \\nThis will do for now. \\n## Performing a Numbers Check - Attempt #1 \\nRight. \\nOur pace is excellent. \\nIn this lesson, we would like to make sure that \\nthe data we've loaded through a join is truly \\nrepresentative of the figures we have in the \\ntwo source files, \\nright? \\nLet's open sheet one and do a few checks. \\nFirst off, I would like to see how many sales \\ntransactions were registered in total. \\nLet's drag the number of records field into the \\nworkspace area. \\nTableau is really quick and tells us that there \\nare 110,570 rows \\nwith transaction ID information. \\nThese are the actual sales of audio books that \\noccurred throughout the entire period ofanalysis. \\nA quick look into the sales Excel file shows us \\nthat this number is precisely the one we should \\nhave. \\nOk, let's change the format of the date of \\npurchase field to date, \\nshall we? \\nI like it much better up here among the \\ndimensions fields and with a calendar icon \\nright next to it, \\nsuggesting this is a date field. \\nNext, I'll test for the number of ratings we \\nhave in the reviews file. \\nI'll simply drop the ratings field into the \\nworkspace area and the result we have is \\n96,897 which is too high. \\nWhy is that? \\nWell, we are summing not counting, \\nthis is the actual sum of all ratings that have \\nbeen left by students. \\nWe want to count the number of ratings instead. \\nHere, that's much better. \\nPeople who bought our audio books left a total \\nof 10,798 ratings. \\nLet's make sure that this number is fine as \\nwell. \\nOk, here it is very well. \\nOne final check and we are good to go. \\nLet's add the date of purchase field to the \\ncolumns of our workspace. \\nMoreover, I'll increase the level of \\ngranularity of our data and we'll opt for a \\nmonthly breakdown. \\nThat's something we can do fairly easily and is \\none of Tableau's strongest features. \\nGranularity is a term that you will encounter \\nquite often while working with Tableau. \\nIt is very important to understand what it is \\nused for. \\nIn fact, it simply refers to the following the \\nlevel of detail in a field of a data set. \\nIn our example, this means taking a daily, \\nweekly, monthly or yearlybreakdown are all different levels of \\ngranularity of the date of purchase field of \\nthe audiobook sales data source. \\nHere's the monthly breakdown of reviews. \\nWait, there is something strange according to \\nTableau, we did not receive any \\nreviews in December 2017. \\nHowever, I do know for a fact that we did. \\nHere's the proof in our Excel file. \\nWhat happened? \\nTableau gets confused pretty easily when we \\njoin the data and then use a dimension \\nsuch as purchase date from the sales file and \\nanother field such as rating from the reviews \\nfile. \\nFor some reason, the date fields of the two \\ntables we joined do not match up with each \\nother correctly. \\nWhenever you experience such issues, it is best \\nto use data blending and alternative to \\ntableau joints. \\nThat's precisely what we will do in our next \\nlesson. \\nThanks for watching. \\n## Blending Data in Tableau \\nData blending is a method of combining data \\nthat supplements a table of data from one data \\nsource with columns of data from another data \\nsource. \\nIn our case, we would combine the sales data \\nfrom the audiobook sales file with the \\nratings column from the audiobook reviews file. \\nHow does blending differ from joining? \\nYou can think of a data blend as a specific \\ntype of left joint that is preferable or \\nnecessary to be applied depending on various \\nconditions. \\nSometimes using a joint will do a perfect job \\nwhile in other situations blending will either \\ndeliver better or quicker results or be the \\nonly solution. \\nMoreover joining data is something you domanually. \\nWhereas data blending is a functionality that \\ntableau implements automatically \\nwhile you are working on your sheet. \\nThis makes it a more intuitive feature to use \\nprovided that the following conditions are met. \\nBoth data tables are separate data sources. \\nThere is a field that serves as the connection \\nbetween them and would allow us to carry out \\nqueries that leverage information from both \\ntables. \\nSo one of the preliminary basic requirements to \\nblend data in tablet is to have a common field \\ncreating the connection between the two \\ndata tables. \\nFrom a technical perspective. \\nWhat blending does is take separate query \\nresults from each data source and \\naggregate them in the view that is in Tableau \\nonly then it will \\nconnect and join the query results on the same \\ncommon field which should contain information \\nof the same data type. \\nThis is different from the case when you are \\nusing a joint where the aggregation is \\nhappening at the database level and just the \\noutput of the joint is being brought back to \\ntableau when blending, the aggregation occurs \\nin tableau. \\nSo what are the benefits of blending data? \\nIt turns out that joining or blending can bring \\ndifferent results. \\nAnd here is the tricky part. \\nIf you join two data tables containing \\nduplicate values that are not aggregated \\nproperly in while doing some preliminary work \\non the data, you will obtain an artificially \\ninflated data set in tableaux \\nblending solves that problem automatically \\ntableau will consider the level of granularity \\nyou have chosen in the view in other words, in \\nyour sheet and will combine the data sources \\nwith aggregated fields directly.OK? \\nI think we are ready to create an actual blend \\nin tableaux. \\nLet's open the audiobook sales file first. \\nThen once I've opened the file, I'll open a \\nsheet and click on new data source from the \\ndata tab. \\nThis is how we will create a new data \\nconnection and we load both files at the same \\ntime without creating a joint. \\nAs we can see here, both files are open in \\nTableau to make sure we've created a blend. \\nI can open the edit relationships, dialogue box \\nand see whether tableaux has created a \\nconnection between the two files. \\nIn our case, things are pretty straightforward \\nbecause Tableau immediately recognized that the \\ntwo files contain columns with the same name, \\ntransaction ID. \\nThe primary data source is the audiobook sales \\nfile which is excellent. \\nThis means it would represent the left table of \\nthe left join performed while blending the \\ndata tableaux. \\nOr alternatively, the view will use all rows \\nfrom audiobook sales audiobook review instead \\nacts as a secondary data \\nsource, the right table. \\nTherefore, while blending tableau will use the \\naggregated rows from this data source based on \\nthe dimension of the common fields. \\nFor the sake of exercise. \\nLet's select the custom relationship radio \\nbutton and choose not one but two different \\nfields that serve as the connection between the \\ntwo files. \\nThis is similar to having a two column, \\nprimary key and a two column foreign key in SQL. \\nI'll click on add \\nand then would like to connect the date of \\nreview and the date of purchase. \\nHm I can't see the date of purchase in here. \\nWhat is the reason?Well, Tableau didn't recognize that this is a \\ndimension and added this field \\namong measures. \\nLet's change its data type and open the edit \\nrelationships window and select to add a \\nnew custom relationship which connects the two \\nfiles based on the date of purchase and on \\nreview date. \\nAnd that's how we edit the relationship \\ntableaux created. \\nRight? \\nLet's switch back to the automatic connection \\ntableau created in our next video. \\nWe'll test whether blending solved the problem \\nwe experienced earlier. \\nHopefully we will be able to combine sales and \\nreviews without any problems. \\nStay tuned. \\n## Performing a Numbers Check - Attempt #2 \\nNow that we have created a blend, we can go \\nahead and make a quick check. \\nThat would allow us to see if the numbers we \\nwill work with. \\nLook fine this time. \\nLet's start with the number of sales \\ntransactions. \\nFirst, I'll simply drag the measure values \\nfield into the workspace area. \\n110,570. \\nPrecisely what we expected. Good. \\nThe number of sales transactions is the one we \\nexpected. \\nNext, I'll remove this field and open the \\naudiobook reviews data to check the number of \\nratings we have, \\nI'll simply drag and drop the rating field. \\nBut this time tableaux displays an error. \\nIt tells us that fields cannot be used from the \\naudiobook reviews data source because there is \\nno relationship to the primary data source. \\nWe find out our data is not blended yet \\nto do that.We have to click on the tiny link icon right \\nnext to transaction id and choose this to be \\nour linking field. \\nThe error we observed previously is not going \\nto appear again because our two data sources \\nare properly linked now. Great. \\nThis is a field that shouldn't be summed but \\ncounted as we are interested in the number of \\nratings left by students and not by the total \\nsum of their ratings. \\n10,798. \\nAgain, the number we expected to see it's time \\nfor the true test. \\nThese numbers were ok. \\nThe last time too, \\nremember, let's plot the number of reviews and \\nthe date of purchase field from the \\naudiobook sales file. \\nAll I have to do is add date of purchase in \\ncolumns and then choose a monthly breakdown \\ninstead of annual breakdown. \\nOh, no, December 2017 is empty again. \\nWhat can we do now? \\nBlending doesn't work either. \\nLet's have some faith. \\nWe'll figure it out. \\nI'll go to data and open the edit relationships \\nmenu here, \\nwe can choose the primary data source which \\nshould be audiobook sales and the fields that \\nserve as a link between the two files. \\nLet's opt for a custom selection and add the \\nfollowing fields. \\nFirst, I'll link the year of review date with \\nthe year of purchase date and \\nthe month of review date with the month of \\npurchase date. \\nOnce we are ready, we can click. \\nOk, and see if the situation changed the same. \\nCheck the count of number of reviews with \\nrespect to purchasing date will show us whether \\nwe've managed to solve the problem by using a \\ndifferent linking field and it appears that ithas here's a timeline that shows the number of \\nratings left each month. \\nWe have 653 reviews for December, not zero. \\nAnd that's excellent. Wow. \\nIt took us a while, \\nbut we figured it out. \\nWe had to edit relationships and adjust the \\nfield that serves as a link between the two \\nfiles. \\nOtherwise we would have been left with a wrong \\ngraph. \\nAnd that would be unacceptable in a \\nprofessional environment as wrong \\nvisualizations lead to wrong business insights \\nin our next lesson. \\nWe'll create the first chart for our dashboard. \\nThanks for watching. \\n## First chart \\nOk, excellent. \\nWe are ready to start with the first chart that \\nwill be inserted in our dashboard. \\nTherefore, I'll rename the worksheet's name to \\nchart one. \\nOk, good. \\nLet's add the date of review information into \\ncolumns and this is where we will be able to \\nsee the timing of purchases and reviews. \\nAs usual, \\nwe are interested in a breakdown by months. \\nSo I'll select month, the workspace area shows \\nus that review dates \\nrange from February 2017 to February 2018, \\nwhich \\nis what we expected to see. \\nLet's insert some data, shall we first? \\nI'll add the number of ratings using the count \\nfunction. \\nEverything's fine and we have data for December \\n2017. \\nSo we can forget about that problem. \\nAccording to our initial plan, this will be a \\nchart that shows the number of reviews and theaverage review score per month displayed on a \\nsecondary axis. \\nSo I'll add the rating field to rose for the \\nsecond time. \\nBut this time we want the average of these \\nnumbers and we would like to create a dual axis. \\nExcellent. \\nObviously, we will have to fine tune the axis \\nscale. \\nA bit as right now, the chart doesn't show a \\nmatch. \\nI'll simply double click and choose a fixed \\nrange starting from eight and going all the way \\nup to 10, \\nwhich is the maximum review score we can have. \\nHowever, right now, the two charts overlap in a \\nstrange way and we are unable to see their \\ntrends. \\nSo I'll increase the size of the axis to 12 and \\nwe'll change the full color of both variables, \\nnumber of ratings and average ratings. \\nThat's easy to do. \\nI need to select one of the two variables and \\nthen click on the color button under marks. \\nOnce we've opened the edit colors menu, we can \\nchoose which variables color we would like to \\nchange to a color. \\nWe like better. \\nI like yellow and blue. Awesome. \\nI'm not really a fan of opacity which adds a \\ntransparency effect and sort of mixes the \\ncolors we have in our chart. \\nTherefore, I'll opt for 100% opacity for both \\nvariables. \\nSee the chart looks nicer. \\nLet's edit its axis again. \\nThat's something which is quite easy to do. \\nWe have to double click on a specific axis and \\ntype the axis title we would like to have, \\nI'll change counter rating to number of ratings, \\nmonth of review date, \\ntwo month. \\nAnd I believe the average rating doesn't needto be changed. \\nVery good. \\nThis is our first chart. \\nDoes it give us any meaningful information? \\nWell, yes, I believe it does. \\nFirst off, we can see that the number of \\nreviews left by people has been increasing, \\nwhich is pretty great. \\nThe average review score is almost nine and \\nsometimes even higher than nine, \\nwhich is a pretty high score but should be \\ninterpreted. \\nAnd compared with the rest of the market. \\nMoreover, we don't see a dependence between \\nnumber of reviews and average ratings, \\nwhich means that average review scores are not \\ninfluenced by the number of people leaving \\nreviews. \\nAll of this is quite interesting. \\nLet's keep up the good work we have been doing \\nin our next lesson when we will create the \\nsecond chart for our dashboard. \\nThanks for watching. \\n## Second chart \\nHi and welcome back in this video. \\nWe'll create the second chart which will be \\npart of our dashboard a pie chart showing the \\npercentage of the total reviews that each \\naudiobook obtained. \\nThe number of reviews is quite important in the \\nmarketplace we are studying and this is the \\nreason why we are interested in finding out \\nwhich audiobooks collected more reviews and \\nalternative visualization would be a pie chart \\nshowing us the percentage of people who \\npurchased a given audio book. Ok. \\nGiven that we know what we would like to \\naccomplish things should be easier, right? \\nI'll add the rating field to the workspace area. \\nThe number we obtained is the sum for all \\nratings. \\nLet's use count for this measure. Perfect.The total number of reviews is \\n10,798. \\nAnd we know for a fact that that is true. \\nLet's go ahead and add the audiobook names \\ndimension above the rating field, shall we? \\nThis creates a breakdown by audiobook exactly \\nwhat we want to have. \\nNow, I can simply select the pie chart icon \\nwithin the show me functionality and I'll \\ncreate a pie chart, a really tiny one but still \\na pie chart to increase the charts \\nsize. \\nI can simply click anywhere in the workspace \\narea, hold the control key and then use the \\narrow keys. \\nIf I press control and up the chart grows \\nvertically while control and right \\narrow increases the charts size horizontally, \\nthe opposite is true as well. \\nWe can decrease the charts size by pressing \\ncontrol and down key or control and left \\narrow. Awesome. \\nWhat else we need labels? \\nRight? \\nOtherwise, it is difficult to gain an idea what \\nportion of overall reviews a specific \\naudiobook accounted for. \\nI'll drag the rating field in label and a \\nnumber of reviews appears right next to each \\naudio book. \\nAgain, we need the count of ratings and not the \\nsum. \\nOk. \\nBut how do we display these as a percentage? \\nThat's not that difficult. \\nActually, all I have to do is go to analysis, \\nselect percentage of and then click on table. \\nBoom. \\nHere we are. \\nThese are the percentages each audiobook \\naccounted for among the total number of reviews, \\nthe pie charts and the labels we added shows us \\nthat audio books, one and two accounted formore than 50% of the total number of \\nreviews the company received. \\nVery interesting. \\nThe business relies greatly on these best \\nsellers. \\nIn our next lesson. \\nWe'll create the third and final chart that \\nwould allow us to complete our initial plan and \\nobtain the dashboard we intended from the very \\nbeginning \\n## Third Chart \\nOk, we are almost there ready for chart number \\nthree. \\nI hope you are. \\nHere we go. \\nIn this lesson. \\nWe would like to create a chart that gives us \\ninformation about the ratio between reviews \\nleft and the number of audiobook \\npurchases in a given month. \\nAn important KP I showing us whether people who \\nbuy audiobooks leave reviews to do that. \\nWe'll need to create a few calculated fields. \\nFirst, let's create a field which counts the \\nnumber of ratings, \\nnot the sum of all ratings, but their count. \\nIt will be much easier if we create this field \\nand use it going forward. \\nThe name of the field we are creating is number \\nof ratings and I simply need to use the \\ncount function. \\nThe next calculated field I would like to \\ncreate is number of purchases. \\nLet's change the data source. \\nWe've selected to audiobook sales here. \\nI will create a field called number of \\npurchases which will contain the number of \\naudiobook sales the company made. \\nHow do I count the number of purchases? \\nWell, the transaction ID code is unique, right? \\nIf we count it, we should obtain the number of \\nsales transactions which is precisely what weare looking for. \\nOk, good. \\nWe are almost ready now, we can create the last \\ncalculated field which will be the ratio \\nbetween reviews and new purchases. \\nLet's do that. \\nIt is a fairly easy task given that we've \\nalready created the number of reviews and the \\nnumber of purchases all we have to do is divide \\nthe two figures and we'll obtain the measure we \\nwant to plot from the very beginning. \\nLet's add it to the rows of our visualization. \\nThe result is a pretty nice bar chart which is \\na bit too large but still looks meaningful. \\nIt appears that the ratio of ratings to new \\nstudents was significantly lower in November \\n2017 and way higher the month before three \\ntimes lower to be precise. \\nI am sure the firm's Business intelligence team \\nwould want to have a look at that and analyze \\nwhat the reason is for this. \\nLet's quickly edit the title of the horizontal \\naxis to month and save our work \\nin our next lesson. \\nWe'll organize the charts we created in a \\ndashboard. \\nStay tuned and thanks for watching. \\n## Creating and Formatting a Dashboard \\nCongratulations on making it this far in our \\nTableau training. \\nLet's take a moment to see how much we have \\ncovered to this point. \\nWe started off by learning when and how Tableau \\ncan be useful in corporate decision making and \\nlearned how to install Tableau's free version \\nTableau public. \\nWe then learned how to connect data to Tableau \\nand what we can do with the different parts of \\nthe Tableau interface. \\nNot long after we created your first Tableau \\nchart, we learned how to duplicate sheets \\nand how to create tables.Then we learned how to create custom fields in \\norder to manipulate our data within tableau \\neasily. \\nIn addition, we learned how to add totals and \\nsub totals to our tables and how to work with \\nfilters. \\nWe explored functionalities allowing us to work \\nwith multiple data sources such as joins and \\ndata blending. \\nAnd most recently, we created three meaningful \\ncharts. \\nNow we are going to build our dashboard which \\nwill be the last piece of the puzzle really. \\nIt will be interesting to put all three charts \\nright next to each other and see the type of \\ninsights we can get by analyzing them in one \\nplace. \\nOK. \\nLet's get right into it to create a new \\ndashboard. \\nI'll click on the tiny icon we have here. \\nSee when we hover the mouse over it, it starts \\ndisplaying new dashboard. \\nOnce the dashboard has been created, my first \\ntask would be to modify its size right now. \\nIt is a bit too small, isn't it? \\nI can adjust the size settings from the left \\npart of the dashboard screen. \\nLet's work with a range that is 1000 pixels \\nwide and has a height of 800 pixels. \\nI hope you are watching this video from a large \\nscreen. \\nOK. \\nLet's drag and drop the three charts. \\nAll I have to do is drag them and place each \\nchart where I want it. \\nTableau is quite smart and manages to find \\nspace and guesses what we want to do when \\nwe position the cursor above the dashboard area. \\nOf course, there are a few things that need to \\nbe adjusted. \\nI'll remove the legends. \\nWe don't need leaving the audiobooks legend.Only moreover, I would like to place the \\naudiobook legend below the pie chart. \\nIt belongs to this way. \\nWhat we are doing will be much clearer. \\nI'll simply press on the legend and then grab \\nthe part you see here, \\ndragging it below the pie chart. \\nLet's resize a bit to get rid of the arrows. \\nPerfect. \\nNow, to remove the arrows of the pie chart and \\nfit it in its allocated space without any \\nproblems we'll need to adjust its size from the \\nchart to sheet. \\nLet's go there and reduce the pie charts size \\njust a tiny bit horizontally and vertically \\nand then we can go back to the dashboard sheet \\nand see what happened. \\nOk, great. \\nThe arrows disappeared. \\nWe are one step closer. \\nLet's change the chart titles a bit because \\nfrankly, they don't mean that much. \\nWe should have done it earlier, but better late \\nthan never. \\nRight. \\nA good title for the first chart would be \\nnumber of reviews and average rating. \\nAlso, I would like to adjust its font size to \\n11 and put the text in bold. \\nWe'll do the same for the other charts too in \\norder to be consistent, \\nwhich is quite important. \\nWhen building a dashboard, \\nthe title of the pie chart would be number of \\nreviews by audiobook, \\nas promised, I'll apply a font size of 11 and a \\nbold text effect. \\nAnd lastly, the title of the third chart will \\nbe ratio of reviews to sales \\nvery well. \\nOur dashboard is almost ready in our next \\nlesson. \\nI will show you how we can add a filter andmake this a truly interactive tool that allows \\nus to dig deeper and filter all three charts. \\nContemporaneously. \\n## Adding Interactive Filters for Improved Analysis \\nOk, guys, we are almost there. \\nOur goal in this lesson would be to add a \\nfilter to our data and be able to look at the \\ndashboard and choose which audio books we would \\nlike to analyze and simply select them from the \\nfilter. \\nSounds useful, right? \\nThe data we see here is quite meaningful and \\nshows us some important trends. \\nHowever, actionable decisions will probably \\nhave to be made at the audiobook level and will \\nneed to be specific for each of the audiobooks \\nour firm sells addressing the story we see here. \\nAll right, let's add a filter to chart number \\ntwo, the pie chart. \\nI'll simply click on the tiny arrow in its \\nright corner containing more options and we'll \\napply audiobook name as a filter again. \\nWe'll have to adjust the charts, \\nsize and position in the dashboard a bit to \\nremove the arrows very well. \\nI think this will do. \\nNow when I use the filter, \\nall changes that occur are for the pie chart, \\nonly the other two charts remain intact as the \\nfilter we just added has no power over them at \\nthe moment. \\nAnd we want to be able to use this filter in \\norder to modify the entire dashboard and not \\nonly one of its charts, how do we do that? \\nLet's select the tiny arrow in the upper right \\ncorner of the filter and go to apply to \\nworksheets where we will be able to click on \\nselected worksheets in the dialog box that \\nopens, I can easily add chart one and chart \\nthree and then press \\nOK. \\nI hope the filter makes changes to all threecharts now. \\nAnd yes, it does nice. \\nHowever, one thing is a bit suspicious when I \\nUN filter the first few audio books, \\nthe ratio of reviews to sales continues to \\ndecrease. \\nAnd this makes no sense. \\nIt appears that right now the ratios are all \\ncalculated with respect to the total number of \\naudio books. Hm. \\nThat's strange. \\nLet's check. \\nI suspect something is not as it should be when \\nI go and take a look at the other two \\ncharts. \\nI see that the blending connection has not been \\nactivated for the audiobook name field. \\nLet's activate the connection for both and see \\nif this changes things. \\nNow when I unfiltered the first few audiobooks, \\nthe percentage doesn't decrease, \\nbut it even goes up. \\nI believe it's fine. \\nNow, please bear in mind the following. \\nIf I would like to use some of the charts \\nelements as a filter, \\nall I have to do is select, use as filter in \\nthe upper right corner of a chart and then \\nall three charts will be updated. \\nThis is another way to play around with filters, \\nwhether we filter data from the actual filter \\nor simply click on a given chart element. \\nIt doesn't make much of a difference in both \\ncases. \\nA filter will be applied. \\nWe've constructed a dashboard that can easily \\nbe filtered and unfiltered from here. \\nNow, we can explore the relationship between \\ndifferent audio books, \\nthe number of reviews they received their \\naverage score and the ratio between reviews and \\naudiobook sales. \\nThat's awesome play around with the data and donot hesitate to share with us the insights you \\nmanaged to uncover great job getting to the end \\nof this exercise. \\nIt was a real pleasure teaching you tableau and \\nwe hope to see you soon in some of our other \\nmodules until then a warm hug and thanks for \\nwatching. \\n## Interactive filters - fix \\nHi, one many of you experience difficulties \\nwith this part of the exercise, \\ncreating filters in this video. \\nOur goal will be to shed some light and \\nhopefully clarify your doubts before applying \\nthe filter to all three charts. \\nYou need to make sure the blending connections \\nare working. \\nGo to chart one and click on data, edit \\nrelationships. \\nThen you need to make sure there is a relation \\nfor audiobook names. \\nOnce this is done, check for all three charts. \\nIf the blending connections are turned on, \\nthey need to be colored in red to make this \\ncheck, you need to click on the data source \\naudiobook sales and click on the icon next to \\nthe audiobook names. \\nOnce the connections are turned on, you will be \\nable to proceeded and add the filter. \\nWhat you need to do is select the pie chart \\nchart two and click on the tiny arrow in the \\nupper right corner. \\nThen select filter audiobook name. \\nIn order to use this filter to modify the whole \\ndashboard, you need to go to the right corner \\nof the dashboard where the audiobook names are \\nplaced again, \\nselect the tiny arrow and click on. \\nApply to worksheets, \\nthen select selected worksheets and mark all \\ncharts. \\nOk. \\nNow the filter should be working properly.Please make a check and see. \\nThat's the case in your own workbook too. \\nThanks for watching.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "string_list_concat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6cad7f0",
      "metadata": {
        "id": "a6cad7f0"
      },
      "source": [
        "### Split the Course Transcript with MarkdownHeaderTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "240ddc1c",
      "metadata": {
        "id": "240ddc1c"
      },
      "outputs": [],
      "source": [
        "md_splitter = MarkdownHeaderTextSplitter(\n",
        "    headers_to_split_on = [(\"#\", \"Section Title\"),\n",
        "                           (\"##\", \"Lecture Title\")]\n",
        ")\n",
        "\n",
        "docs_list_md_split = md_splitter.split_text(string_list_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eb00c463",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb00c463",
        "outputId": "177d12d5-2b17-4510-aa67-d1376ff9e3da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(docs_list_md_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30478d0f",
      "metadata": {
        "id": "30478d0f"
      },
      "source": [
        "### Create a Chain to Correct the Course Transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e8ca5fb5-1a22-4472-a48b-851dd0a9c733",
      "metadata": {
        "id": "e8ca5fb5-1a22-4472-a48b-851dd0a9c733"
      },
      "outputs": [],
      "source": [
        "string_list_split = [i.page_content for i in docs_list_md_split]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "66e11ea6-5d15-49ad-964f-3c150787317a",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66e11ea6-5d15-49ad-964f-3c150787317a",
        "outputId": "07c20399-2014-4371-9fa6-dfcd3f5a28e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Hi, everyone.\\nI'm Ned and I'll be your instructor for this\\ncourse.\\nTableau is an invaluable tool.\\nOne needs to learn on their journey to become a\\nsuccessful business intelligence analyst or\\ndata scientist.\\nThe art of these professions is storytelling\\nusing data to tell stories and convince top\\nmanagement of the right course of action.\\nBy completing this part of the program, you\\nwill know how to create charts and dashboards\\nin tableaux.\\nThis is an essential step on your way to a data\\nscientist role.\",\n",
              " \"Tableau has grown to become one of the most\\npopular business intelligence tools in the\\nentire world.\\nIt is A B I software that allows non technical\\nusers to visualize their data and work with it\\nalmost immediately lowering,\\nknow how barriers dramatically in the past.\\nBusiness analysts needed the help of it\\npersonnel who could assist them in gathering\\nraw data and preprocessing it.\\nOnly then could business analysts start working\\non the visualization of such data?\\nThe advent of Tableau democratized this process\\nand allowed B I analysts to be\\nindependent non-technical people can easily\\nload data into the program and start playing\\nwith it.\\nTableau's forte are meaningful intuitive\\nvisualizations and sometimes that's really\\nvaluable analysts are able to explore their\\ndata right away without spending too much timeon numbers which provide limited insights and\\ninstead focus on data that matters.\\nThis is why we can confidently say that Tableau\\nis an indispensable tool in the arsenal of most\\ncorporate business intelligence analysts,\\ndata analysts and data scientists.\\nMany people are uncertain about the difference\\nbetween Tableau and spreadsheet tools\\nlike Excel.\\nAnd that's a reasonable doubt until we point\\nout they serve different purposes using\\ntableaux doesn't necessarily mean you can\\nforget about Excel and vice versa while Excel\\nis not as powerful or\\nintuitive as tableau.\\nWhen it comes to data visualization,\\ntableau is not optimal when you would like to\\nuse it as a data creation tool.\\nAlthough it has several database management\\nfunctionalities, the program isn't the best\\nsolution when you would like to perform\\nmultiple operations with your data before you\\nstart analyzing it.\\nMoreover, tableau isn't great for multilayered\\ncalculations.\\nIt is able to calculate in its own fields, but\\nit shouldn't be used as a spreadsheet tool for\\nmultilayered calculations such as the\\npreparation of a budget in Excel where tableaux\\nsurpasses the competition is in data\\nvisualizations.\\nIt is a very smart program that allows you to\\nvisualize data in a more powerful way compared\\nto Excel.\\nSo for example, when you work with geographical\\ndata, there is no way Excel could interpret the\\ncells in your spreadsheet as a geographical\\nlocation.\\nOn the other hand, Tableau recognizes that and\\nallows you to visualize such data and see how a\\nvariable is distributed geographically.\\nMoreover, tableaux allows you to combine\\nseveral types of charts and build up meaningfuldashboards that are truly interactive and\\nfacilitate additional analysis.\\nOnce you visualize your data, you can easily\\ndig deeper and explore its granularity,\\nfinding the reason for unusual spikes or\\ninvestigating certain trends.\\nEven novice tableau users would be able to save\\na significant amount of time if they transfer\\ntheir pre designed existing Excel dashboards to\\ntableau uploading new data and\\nupdating visuals is more rapid in Tableau.\\nTherefore, we can agree that a competent\\nanalyst needs both Excel and tableaux.\\nGiven that they serve different purposes.\\nTableau is superior when it comes to visuals\\nand dashboards and Excel is a spreadsheet\\ntool we need in order to perform multilayered\\ncalculations in the same way,\\na combat soldier carries a rifle and a pistol\\nat the same time and uses them under different\\ncircumstances.\\nA business analyst should know how to work with\\nboth Excel and tableaux and apply each of them\\nwhen needed.\",\n",
              " \"Ok, guys, it is time to get started with\\nTableaux.\\nLet's type Tableau public in Google.\\nAs you can see the first result, we have points\\nto Tableau's website at www\\ndot tableau dot com.\\nI'll click on the link and this will direct me\\nto the Tableau public Domain.\\nIt shouldn't be too difficult to download\\nTableau from here if you are wondering why we\\nsearched for Tableau public.\\nThe reason is quite trivial.\\nThis is Tableau's free version if you don't\\nhave a paid subscription for Tableaux.\\nThis is an excellent alternative.\\nYou can practice with most of the program's\\nfunctionalities and you don't have to payTableau's annual fee.\\nSo it is up to you.\\nYou can either use Tableau public for free or\\npay for Tableau's desktop version.\\nBoth options would allow you to follow along.\\nThere are some issues when you want to\\nintegrate Tableau public and programming\\nlanguages like R, Python and SQL to do that,\\nyou'll need Tableau\\ndesktop.\\nBut for now, Tableau public will do just fine\\nand allow us to practice at will all I have to\\ndo here is provide an email address.\\nAnd once I have done that, an exe file will\\ndownload automatically on my computer.\\nLet's open the EC file.\\nThis is the standard installation procedure you\\nwill find when installing any program out there.\\nI have to agree to Tableau's terms and\\nconditions and then click install.\\nOnce the installation starts, I simply have to\\nwait.\\nAnd here we are, Tableau is installed on my PC.\\nWe are ready to start our journey.\",\n",
              " \"Right. Great.\\nHere is our freshly installed version of\\nTableaux.\\nI am sure you are anxious to create some\\nfascinating visualizations.\\nSo let's get started.\\nFirst off, we need to learn how to connect\\nTableau to the data source we will be working\\nwith.\\nThere are two options, we can either create a\\nconnection to a file or a server.\\nOf course,\\nwe'll choose one of the two depending on where\\nthe data is.\\nLet's connect Tableau to a Microsoft Excel file\\nin general.Every time we use a source file in one of the\\nlectures, you will be able to find it in the\\nsupplemental resources section.\\nJust open your course curriculum and download\\nthe available files for that lesson.\\nSee, OK, great.\\nI'll select the file called GDP data and under\\nconnections.\\nI can now see that Tableau opened the file.\\nOur source has three sheets, data, metadata,\\ncountries and\\nmetadata indicators.\\nWhat we usually have to do is choose the\\nworksheet we'll need and drag into the upper\\npart of the screen where drag sheets here is\\nwritten.\\nOnce we do that tableaux is going to activate\\nthe sheet we selected and provide us with a\\npreview of the data we have inside the first\\ntwo rows of the sheet are empty.\\nAnd hence, we see all of these null values\\ntableaux is really smart\\nand can often help us with similar issues.\\nAs you can see here, the program suggests using\\nits data interpreter functionality\\nto clean the data.\\nAll right, let's do that.\\nAnd voila the first two rows containing no\\nvalues disappeared.\\nThat's awesome.\\nIn our next video, we'll open our first tableau\\nworksheet and I'll be happy to introduce you to\\nits structure.\\nThis will do for now.\\nThanks for watching.\",\n",
              " \"So we've already connected our file to tableaux.\\nNow, in this lesson, we'll be creating our\\nfirst sheet.\\nIt's really easy to do and resembles how we\\ncreate a sheet in Excel or pretty muchevery other spreadsheet software.\\nAll I have to do is click here and a new sheet\\nwill be created, right?\\nThis is what a Tableau sheet looks like.\\nWe can have as many of them as we want.\\nI can simply click on this little icon at the\\nbottom and a new worksheet is added.\\nThe other two icons which are next to it are\\nfor creating a new dashboard and a new\\nstory.\\nWe'll deal with dashboards further in the\\ncourse.\\nSo we won't use these buttons for now.\\nOK.\\nLet's give some structure to what you are\\nseeing here.\\nIf this software is new to you,\\nthings can be a bit confusing.\\nSo it will be best if we spend a few minutes.\\nThe remainder of this lesson talking you\\nthrough Tableau's interface.\\nFirst off, we have 10 different tabs on\\nTableau's default ribbon.\\nThese are file data worksheet dashboard,\\nstory analysis map format window\\nand help.\\nLet's quickly go through each of them.\\nAs with most programs, the file tab contains\\ncertain functionalities related to opening,\\nclosing and saving files if you would like to,\\nyou can also exit tableau from here.\\nBut why would you want to do that data?\\nOn the other hand is where you will find\\nfunctionalities related to the data source you\\nare using here,\\nyou can add a new data connection, replace an\\nexisting one or simply edit the data\\nsource of the worksheet you are working with.\\nNext, we have the worksheet tab.\\nIt can be helpful when we want to create a new\\nworksheet hide or show a charts,\\ntitle caption summary and so on.\\nI am sure you noticed that we already created anew sheet with the little icon we have at the\\nbottom left corner of the sheet and we can do\\nthe same thing from the worksheet tab as well.\\nSuch repetition is common for most programs,\\nfunctionalities available in the ribbon\\ncan be accessed in other ways too.\\nIn fact, I rarely use the ribbon\\nfunctionalities, but it is good to have an\\noverview and be aware that they are there.\\nOK?\\nNext, we have the dashboard and story tabs.\\nAs I said, we'll learn more about dashboards\\nand stories later on.\\nIn the course, the analysis tab is where you\\ncan tweak your visualization in terms of\\nlabels, show figures as a percentage of the\\ntotal add trend lines,\\nlegends filters and more.\\nWe'll explore many of these options later in\\nthe course for now,\\nyou can remember that here, we have some\\ninteresting functionalities related to the way\\nwe perform our analysis.\\nAnd some of the tools we'll incorporate in it\\nmap is a tab that is helpful when we use\\nTableau's geographic visualization capabilities.\\nPretty soon.\\nYou will see that this is one of the most\\npowerful and impressive tableau features.\\nOf course, format can help us adjust the way\\nour visualization appears from here.\\nWe can modify its font, font size, axis,\\nbackgrounds,\\nlabels, size and so much more.\\nThat's another tab containing plenty of useful\\nfunctionalities.\\nWe'll explore later windows and help are two of\\nthe standard tabs we find in most\\nprograms.\\nSo I am not going to spend much time on them\\nalso because we are not going to use them\\nthroughout the course.\\nHowever, one thing we should mention is thatTableau public has a nice and open community of\\nusers who will be able to help you and whose\\nwork you can look at if needed,\\nall users of Tableau public who save their work,\\nmake it publicly available.\\nTherefore, this can be a useful place where you\\ncan search for a given issue you need help with\\nand see what comes up.\\nSo if I click on community and search for\\ngeography, I'll be able to see the\\nwork other users have saved previously, right?\\nThis is Tableau's ribbon\\nbelow the ribbon, we have several buttons that\\ncan be quite helpful.\\nThe show start page button takes us to the\\nscreen we saw previously when we connected\\ntableaux and our GDP data Excel file to get\\nback to the sheet that was created earlier.\\nI'll click here.\\nI'm sure you know how to work with undo and\\nredo.\\nSo if I were to drag one of the fields here, I\\ncan go back and undo this section with\\nundo.\\nOf course, see undone.\\nMost of the typical windows shortcuts can be\\nused here as well as you probably know.\\nThe shortcut for undo is control Z.\\nOn the right, we have other useful buttons such\\nas save,\\nallowing you to save the progress of your work.\\nQuite intuitively.\\nNew data source opens the connect functionality\\nwe saw earlier.\\nThe other buttons we have here are new\\nworksheet, clears,\\nsheet swap rows and columns, sort and so on.\\nWe'll explore many of these throughout the\\ncourse for now,\\nit would be best if you simply gain an idea how\\nvarious objects are positioned within Tableau's\\ninterface. OK.\\nOn the left side of Tableau's screen,we have two pas data and analytics.\\nThe data pane is quite important.\\nIt shows us what data we've loaded and then\\nTableau classifies the data into two\\ntypes dimensions and measures to put it\\nslightly differently.\\nThis is a distinction between categorical and\\nnumerical data.\\nThe data in the dimensions field cannot be\\naggregated.\\nIt is qualitative in nature.\\nQuite the opposite measures can be aggregated\\nand are quantitative in nature.\\nIn the next few lessons, we'll learn how to\\nwork with these fields.\\nBut for now, it would be nice if I just show\\nyou that we can drag dimensions and measures\\ninto the work area and use them to create our\\nvisualizations there.\\nThe work area is where we'll create our\\nvisualizations, dashboards and stories and\\nthis is one way to create a chart.\\nI am sure you noticed that the columns and rows,\\npart of the sheet started showing us the\\nvariables we've added to the workspace area.\\nWe'll explore this part of the interface in a\\nseparate video in a few lessons.\\nOK. Perfect.\\nWhat else do we have the show me button on the\\nright, which allows us to adjust the type of\\nvisualization we use.\\nIt is a very cool feature because tableau tells\\nus what types of visualizations we can\\nchoose from as not all charts will be available\\ndepending on the data we have chosen to work\\nwith.\\nOnce we decide we would like to switch to a\\ndifferent chart, all we need to do is select\\nthe respective type of chart and tableau makes\\nthe adjustment for us neat, right?\\nAnd finally, here in the middle, we have three\\nimportant sections,\\npages, filters and marks the pages shelf.Lets you\\nbreak a view into a series of pages.\\nSo you can better analyze how a specific field\\naffects the rest of the data in a view we'll\\nuse the filter shelf when working with\\nfilters and filtering our data.\\nThe marks shelf on the other hand contains\\nfunctionalities related to coloring size\\nlabels and so on.\\nThis lesson was a quick overview of Tableau's\\ninterface.\\nI am sure now you have a better idea of what\\nyou see in front of you.\\nWhen you open the program in the lessons to\\ncome, we'll continue to explore Tableau's\\nfunctionalities and you'll learn a ton about\\neach of the buttons we mentioned here as of now,\\nthis will do.\\nThanks for watching.\",\n",
              " \"All right, excellent.\\nIt is time to continue our adventure in\\nTableaux.\\nIn this lesson, we'll create our first\\nvisualization and it is going to be awesome\\nready.\\nLet's get right into it.\\nThen as you can see the workspace area is empty\\nright now,\\nwe've already loaded the GDP data file and we\\ncan see that here.\\nActually, let's open the GDP data XL file for a\\nsecond.\\nI want to make sure you are familiar with its\\nstructure here.\\nIt is we have a few blank rows but tableau took\\ncare of them.\\nThen we have a column with country names, a\\ncolumn indicating that this is\\nGDP data and several columns with GDP figures\\nfor each of these\\ncountries.And this is the data sheet we are using right\\nnow. Perfect.\\nLet's go back to tableaux.\\nThe way data is organized here is rather\\ninteresting.\\nOur attention should be focused on the\\ndimensions and measures part of the screen.\\nFirst off, we notice that tableau has been very\\nsmart and managed to organize our\\ndata.\\nCategorical variables are right here under\\ndimensions.\\nWhile numerical data such as the country's\\nactual GDP is under measures dimensions have\\nbeen colored in blue\\nand measures are in green. OK.\\nAnother important remark we have to make is\\nthat some of the fields we see here are in\\nitalics and others aren't the distinction\\nbetween the two is that tableau generates\\ncertain fields based on the data.\\nIt finds when tableau generates its own fields\\nsuch as the measure names field we see here.\\nThese are fields that are not contained in\\nour original data source, But tableaux deems\\nthat these can be useful and creates\\nthem for us.\\nThe same thing is true for latitude,\\nlongitude, number of records and measure values\\nwe see in green\\nunder measures.\\nThe rest of the fields written without italics\\nare ones we saw in the XL file.\\nWe loaded country name, indicator name and the\\nyears from 2002 to\\n2016 where we have country's GDP figures. Good.\\nAnother important detail I would like to\\nmention is that tableaux adds an icon right\\nnext to each of the fields we have under\\ndimensions and measures.\\nThis is what allows us to understand how\\ntableau reads the data.\\nThe first field under dimensions is countryname and its icon is the\\nglobe.\\nTableau recognizes that this field is related\\nto actual countries and it is ready to help us\\nout when we need to visualize such data.\\nIf I click on the icon, I'll be able to see\\nthat this is a string and that its\\ngeographic role is of country region as it\\nshould be.\\nAt the same time, the tiny ABC icon of the\\nindicator name field shows us that\\nthis is a text value.\\nAnd in fact, when I click on it, I can see that\\nthis is a string but different to what we have\\nfor the country name field.\\nThe geographic role of indicator name is none.\\nThat's because this is purely a text value.\\nWhat about the year measures we have below?\\nWell, these are numerical values, right?\\nTherefore, it comes as no surprise that when we\\nclick on their icon,\\ndesignating numerical values, we will see these\\nare numbers.\\nOK? Perfect.\\nLet's do the following.\\nI'll drag the country name field into the\\nworkspace area and boom\\nTableau created a world map that shows us the\\nlocation of each of the countries we have in\\nour data source.\\nIt is quite interesting to see that the field\\nwe see under columns and rows isn't country\\nname but are artificially generated longitude\\nand latitude fields.\\nAt first, it may seem strange but then when you\\nthink about it,\\nit is intuitive.\\nTableau understands country name is a\\ngeographical field.\\nThis is why it will do much more than simply\\ncreate a row or a column containing a list of\\nthe country we have in the Excel file.\\nNo, the program is smarter than that.It reads the country names and then creates the\\ntwo fields,\\nlongitude and latitude in order to map each\\ncountry geographically and hence the\\nbeautiful map we have here.\\nNow, if I drag the year 2016 in the map,\\ntableau will update the\\nchart adding the 2016 GDP of each country.\\nWe can see that happen.\\nIf we hover above each of the dots we have\\nrepresenting the countries on our map.\\nSee the US GDP for 2016 was more than $18\\ntrillion while Canada's GDP was around $1.5\\ntrillion.\\nOK. Perfect.\\nEverything's good.\\nOur first visualization and Tableau is almost\\nready.\\nOne last finishing touch I would like to add is\\nto enlarge the bubbles a bit indicating how\\nlarge a country's GDP is to\\ndo that.\\nI can work with the newly appeared sum 2016 pan\\non the right side of the screen, I'll click on\\nits tiny arrow and we'll select\\nedit sizes, the edit sizes, dialog box allows\\nme to enlarge the bubbles we see in\\nthe visualization.\\nI think this will do let's click apply.\\nAnd as you see the bubbles in the visualization\\nincreased.\\nThis makes it a bit easier to compare the GDP\\nof different countries.\\nThe final touch will be to edit the name of\\nthis visualization.\\nI'll double click here and simply type a title.\\nAnything is better than sheet one.\\nThat's why I'll simply type GDP per country\\ncomparison.\\nAnd here we are, that's our first visualization\\nin Tableau and we are just getting\\nstarted# Tableau Functionalities\",\n",
              " \"Ok, perfect.\\nIn this lesson, we'll continue exploring some\\nof Tableau's main features in particular, we'll\\nlearn how to create a table with data\\nand add some custom fields.\\nThe table we will create is going to be a\\npretty simple one,\\nproviding a monthly and yearly breakdown of a\\ncompany's sales.\\nAs you can see, our original data source\\ncontains a column called period.\\nThis is where we have both yearly and monthly\\ndata.\\nThe first four characters designate the year\\nwhen a sale was made and then the last two\\ncontain information about the month when the\\nsale occurred.\\nWhat I would like to do is split this\\ninformation into two separate custom fields,\\nyear and month.\\nThe way to do that is to go to the analysis tab\\nand create a calculated field,\\nright?\\nOnce this dialog box opens, I'll type the name\\nof the field I am creating which is year.\\nThen I'll use the left function in order to\\ntake the four leftmost symbols of\\nthe period field.\\nThis is where we have the year when the sale\\noccurred.\\nLeft is a function.\\nMost of you are probably familiar with in\\nTableau.\\nIt works in the exact same way as it does.\\nIn Excel.\\nFor example, in our next lesson, we'll pay\\nextra attention to the different types of\\noperations you can do to create custom fields.\\nOK?\\nTableau recognizes we are writing the leftfunction and it helps us with autocomplete\\nsuggestions.\\nThe left function needs two arguments from us a\\nstring which in this case\\nis the period field we have in our source sheet.\\nIt is important to make sure that the period\\nfield, data type is a string otherwise\\ntableau will show an error.\\nSo I'll type period.\\nAnd as I do that, tableau manages to recognize\\nI'm referring to the period field and\\nallows me to select it right away.\\nThe second component of the formula is the\\nnumber of characters we would like to extract,\\nwe'll need four characters and that's what I'll\\nwrite here,\\nclose the brackets and our new field is ready.\\nIf the period field was not of the string type,\\nwe would have had problems because\\nleft is a function that requires us to use\\nstrings, I'll change the data type of the\\nperiod field.\\nAnd as soon as I do tableaux shows us a warning\\nsign next to the newly generated field year.\\nAnd it doesn't allow us to drag this field into\\nthe workspace area.\\nBasically, we can't use it. OK.\\nI'll change the type of data of the period\\nfield back to string and the issue will be\\nresolved.\\nNow, I can easily drag the year field into the\\nworkspace area.\\nSee, perfect.\\nThe other field I would like to create is month.\\nAnd in order to do that,\\nI'll use the right function again, we'll need\\nto go to analysis and create a calculated\\nfield.\\nFirst, we'll assign it with a name months and\\nthen I'll type in the right function following\\nthe exact same procedure as before\\nthe string we'll need is the same period.\\nand the number of characters we'll need is two,given that months are the two\\nrightmost characters within the period field.\\nExcellent.\\nNow that we have our second field months,\\nlet's add it right next to years in the\\nworkspace area.\\nI can do that in two ways.\\nI can either drag the field into the workspace\\narea and place it right next to the year's\\ninformation or alternatively drag the month\\nfield right next to the year's field in the\\nrows.\\nPart of the screen, the output is the same.\\nNow, we should create a new calculated field\\nand name it number of\\nrecords in the box below.\\nWe will just type the number one and press.\\nOK?\\nThis field represents a simple count of the\\nrows we have in our source data.\\nOK? Great.\\nWe've managed to create a nice table that\\ngroups all 12 months of 2016 and\\nall 12 months of 2017.\\nI'll simply insert the number of records field\\nwe just created and voil.\\nThis is a nice table that shows us the\\nbreakdown of the company's total number of\\nsales for each month in 2016 and 2017. Awesome.\\nRight.\",\n",
              " \"We already know how to create custom fields.\\nWe did it two times in our previous lesson,\\ncreating the years and months fields.\\nIn this lesson,\\nwe'll spend some time describing some of the\\nother ways you can transform your source data\\nand create custom fields.\\nRemember, we shouldn't go too far with these as\\nTableau's main purpose is visualization and not\\ndata creation or modeling.\\nHowever, sometimes it can be really handy toperform certain manipulations once we've loaded\\nour data into tableaux and we need a certain\\ntype of analysis.\\nOK.\\nHere we go.\\nThe typical Tableau operators you'll need to\\nremember are plus for addition,\\nminus for subtraction star for multiplication\\nforward slash for division\\nand carat for elevation alongside these, you'll\\nprobably need comparison operators\\nsuch as equal, higher, then lower than higher\\nor\\nequal and different.\\nThen the logical functions available in Tableau\\nare like the ones we have in Excel and or and\\nnot a lot of the\\nfunctions and symbols used in Excel can be used\\nwhen creating a calculated field.\\nSo for example, some of the most commonly used\\nfunctions are some for some\\naverage for average min and max allowing you to\\nfind the minimum and maximum\\nvalues within a range.\\nAnd A BS returning the absolute value of a\\nnumber.\\nAnd we already saw the text functions left and\\nright.\\nThey allow us to extract a leftmost and a right.\\nMost number of characters within a string we've\\nspecified besides left and right.\\nWe can also use the typical text functions\\navailable in Excel Mid providing us characters\\nthat are in the middle of a text string, upper\\nand lower allowing us to either convert it to\\nall upper case characters or convert it to all\\nlower case characters.\\nThis was a nice recap of the types of operators\\nwe can use in order to create custom fields in\\ntableaux.\\nFor more information on this topic,\\nwe'll add a downloadable file attached to thislesson.\\nThanks for watching.\",\n",
              " \"Right.\\nSo we are ready to go back to Tableaux and\\nperform a few additional operations with the\\ntable we created earlier right now.\\nIt shows us the number of units sold by the\\nfirm in each month of 2016 and 2017.\\nLet's change this measure.\\nWhat I would like it to show us is the revenue\\nthe company generated during each of these\\nperiods.\\nHow can I do that?\\nWell, it's fairly easy.\\nOur source data contains information about\\nprice and tableaux counted.\\nThe number of units sold each row shows us a\\nsingle car sale, right?\\nTherefore, if we multiply the price field and\\nthe auto generated number of records\\nfield, we would obtain revenues.\\nDo you agree?\\nOk, good.\\nLet's do that.\\nWe already know how to create a calculated\\nfield.\\nI'll name it revenue and we'll take advantage\\nof Tableau's autocomplete suggestions by\\nmultiplying price and number of records.\\nSee as we said in our previous lesson, we can\\nuse the star operator to carry out a\\nmultiplication.\\nOne very useful feature you have probably\\nnoticed is that at the bottom of the screen\\ntableau tells us whether the calculation we've\\nentered is a valid one or not.\\nRight now, my calculation is valid if I remove\\na few symbols tableau would indicate\\nthat the calculation contains errors.\\nThis is a good guiding light when we create a\\ncalculation, right.So this is our revenue field,\\nwe can easily substitute the number of records\\ndata in the table with it.\\nAll I have to do is drag the revenue field and\\nposition it over the number of records data\\ntableau replaces the two fields. Perfect.\\nAn important metric contained in our source\\ndata is gross profit.\\nBy definition, revenue minus cogs equals gross\\nprofit.\\nCurrently, we have revenue and gross profit.\\nLet's calculate cogs as the difference between\\nthe two.\\nThat's easy to do.\\nAll we have to do is use the minus operator.\\nNice.\\nLet's order our table in the following way.\\nFirst we'll have revenue then cogs and finally\\ngross profit.\\nI can do that by dragging and dropping the\\nthree fields within the table.\\nPlease note that their values appear in the\\nmeasure values card on the left side of the\\nworkspace area, we can change their order\\neither from here or directly inside the table.\\nIt's up to you.\\nOne more thing you have probably noticed the\\nmeasure names field which appeared in the\\ncolumns section.\\nThis is an auto generated field tableau uses in\\norder to form our table and separate the\\nnames of different measures.\\nIf we were to remove it from the column section,\\nthe table will lose its shape and all three\\nmeasures will be put together.\\nLet's press control and Z and undo this action.\\nOK. Excellent.\\nIn our next lesson, we'll learn how to add\\ntotals and subtotals to our tables in tableaux.\\nThis will do for now.\\nThanks for watching.## Adding totals and subtotals\\nMost executives and by most, I mean, all of\\nthem prefer receiving tables that contain\\ntotals and subtotals.\\nThis makes it easier for them and helps them\\ndigest information in a faster way.\\nIn this lesson, we will learn how to add totals\\nand subtotals to our tableau tables.\\nThat's nice because the table we have been\\nworking on in the last few videos doesn't\\ncontain totals for 2016 and 2017.\\nWe'll add them in this video.\\nThat's fairly easy to do.\\nI'll go to analysis then totals and we'll\\nselect show column,\\ngrand totals.\\nThe totals we just added are for the entire\\nperiod 2016 and 2017.\\nThat's not really useful.\\nIs it whenever a person is interested in a\\ncompany's sales or gross profit, they want to\\nknow how much it made in a specific year and\\nwhether it performed better than the year\\nbefore a company will also want to know how its\\nyear's sales compare to other companies.\\nSo I'll go to analysis totals and unclick the\\nshow column, grand totals to remove the total.\\nWe just added what I can do differently.\\nThe second time around is opt for add all\\nsubtotals.\\nAnd this will give me the total figures for\\n2016 and 2017\\nseparately.\\nQuite nice.\\nRight now, we can read the table easily the\\nfictitious numbers we see here,\\nhelp us compare 2016 and 2017 and give us a\\ngood idea of what the\\nactual sales were for that period.\\nIn our next lesson, we'll add percentage, gross\\nmargin to our table.\\nThanks for watching.## Adding a custom calculation\\nOk, excellent.\\nWe're doing good.\\nWe've seen quite a few interesting tableau\\ntools so far and we'll continue to do so during\\nthis lesson as well.\\nOur table is almost ready.\\nWe have revenue cogs and gross profit.\\nNow that I think about it, one thing we should\\nprobably add is a gross margin calculation\\nright next to the gross profit figures.\\nGross margin is useful because it allows us to\\nsee what portion of revenues were converted\\ninto gross profit once we have considered the\\ncost of goods sold.\\nRight.\\nLet's add a new calculated field.\\nI'll name it GM percent.\\nAll we have to do is divide gross profits by\\nrevenue, right?\\nAnd we already know how to do that. Ok.\\nHere we are.\\nWe've calculated a new field.\\nLet's add it to the table.\\nI'll insert it in the measure values card there.\\nI've added the new field right next to gross\\nprofit.\\nBut it looks strange, doesn't it?\\nIf we divide gross profit by revenues, we would\\nusually expect a number in the region of 10,\\n2030 or maybe 50%.\\nCertainly not 1000.\\nWhat is going on here when I divide 71 million\\nby 244 million,\\nwhich is what we have in January.\\nI obtain 29%.\\nApproximately.\\nThere are two possible explanations.\\nEither tableau miscalculated, the simple\\ndivision we asked it to perform or our formula\\nis not 100%. OK.It's most likely us and not the computer, right.\\nI'll take out the GM percent field from the\\nmeasure values box and we'll edit the\\ncalculated field from here.\\nWhat we forgot to do is type sum around the two\\nvariables.\\nIf we don't sum the variables, we are not\\ndividing their total figures for each month.\\nLet's adjust our calculated field in this way\\nand see what happens.\\nOK?\\nThis is a column with numbers that look like\\nzeros, but perhaps these are percentage values.\\nLet's change the way the GM percent\\ncolumn is displayed to do that.\\nI'll simply click on the GM percent variable in\\nthe measure values card and select the format\\noption.\\nWe have quite a few options available here.\\nSo I'll simply select a percentage format with\\none decimal place.\\nVoila.\\nOur table is ready in our next lesson.\\nWe'll add a filter that would allow us to\\nchoose whether to see both 2016 and 2017\\nvalues or just one at a time.\\nSee you there.\",\n",
              " \"One of the most interesting options available\\nin tableaux is adding a filter to the\\nvisualization you are working on in this lesson,\\nwe'll learn how to do that.\\nOf course, we'll add a filter to our table from\\na user standpoint.\\nThe only field which makes sense to be filtered\\nin this table is the year field.\\nA person could be interested in seeing numbers\\nfor 2016 or 2017\\nonly.\\nFor example.\\nSo what I'll do is select the analysis tab andthen select filters,\\nchoosing the year field.\\nAs we had already decided,\\nwe would like to create a filter for years.\\nAnd as we do that, a filter appears on the\\nright side of our workspace area.\\nNow, we can easily hide 2017.\\nFor example, I'll simply untick its\\nvalue and everything related to 2017 disappears\\nfrom the sheet\\npretty cool.\\nRight?\\nOf course, we can do the same with 2016.\\nI'll select 2017 and unti 2016.\\nAnd here we are.\\nWhen we click on the tiny arrow which is in the\\nupper right corner of the filter pane,\\nwe find plenty of options that allow us to\\nadjust the filter we've created.\\nFor example, we can change its appearance to\\nsingle value list,\\nrepresenting radio buttons have a filter as a\\ndrop down menu,\\na multiple values list and so on and so forth.\\nWe can easily change the filters formatting by\\nselecting format filters.\\nOr alternatively, we change the filters title\\nby clicking on the edit title button.\\nWhat else can we do?\\nOh, yes.\\nWe can choose whether to apply the filter to\\nthe current working sheet only or to all\\nworksheets in the tableau file we are working\\nwith.\\nAnd that's really useful when working with\\nseveral interrelated sheets. OK.\\nThis was our short introduction to filters in\\ntableaux.\\nThis will do for now.\\nThanks for watching.## Working with joins in Tableau\\nOne of the most important aspects of your work\\nin tableaux is the data source you are using to\\nperform analysis quite often, the data will be\\nstored in multiple locations and hence,\\nyou will have to deal with a number of data\\nsources which live in different environments.\\nNevertheless, you are going to want to use all\\nof the data available to you and run analysis\\non everything together.\\nThe way we merge multiple data sources is by\\nusing joins for those of you who have already\\nfollowed our program and especially our SQL\\nvideos you'll be familiar with what follows in\\nthis video.\\nSo feel free to skip or continue watching as a\\nrefresher for the rest.\\nPlease follow along when we want to perform\\ncross data table joins.\\nWe want to combine two or more data tables to\\ncreate a unique database.\\nHow do we join separate data tables?\\nWell, there are a few ways to do that.\\nWe can create an inner, outer left or a right\\njoint.\\nLet's open an Excel file to demonstrate a bit\\nbetter what each type of joint represents.\\nHere, we have two very simple tables.\\nThe first one shows us the age of three\\nbasketball players and the second one shows us\\nthe salary of basketball players.\\nPlease note that the two tables are different\\ndue to their last rows.\\nWe have lebron James in the first one and Kyrie\\nIrving in the second.\\nOk, let's say we would like to run some\\nanalysis and use the data available in both\\ntables.\\nTherefore, as described earlier, we have to use\\njoints.\\nBut how do we do that?\\nWe can easily see that the two tables have one\\ncolumn in common.The basketball player column, this column will\\nserve as a key.\\nWhen we put together the information from both\\ntables, a left join would mean that the left\\ncolumn of the first table will lead the way we\\nwill use it to create a table containing\\nage and salary information about the three\\nplayers we see here.\\nWhenever we find one of these players to the\\nright, we'll add their salary in the new table.\\nAs you can see here if their name is not\\npresent to the right,\\nwhich is the case with lebron james' salary, we\\nwill have a null value in the table.\\nIf a player's name is not present in the left\\ncolumn of the first table,\\nwe will not include any information about them\\nas this is a left join and any rows\\nwhich are not present in the key field of the\\nleft table are omitted in the new table.\\nA right join functions.\\nIn the same way.\\nHowever, this time, the left column of the\\nsecond table leads the way Kyrie\\nIrving replaces lebron James who is not present\\nin the left table.\\nHence, the only missing value would be Kyrie\\nIrving's age.\\nGiven that the only information we have about\\nhim is in the right table.\\nThe case when we are interested in the\\nintersection of the two tables only is called\\nan inner join.\\nThis is when we create a table that contains\\nrows where we have an exact match between the\\nkey fields we are joining the two tables with\\nin our case,\\nbasketball player.\\nThis time, the newly created table contains two\\nrows, only,\\nboth tables contain information about these\\nplayers.\\nHence, this is an inner join.An outer join would be the opposite case we add\\nall rows of the two tables regardless of\\nwhether there is a match in the key field we\\nare linking with.\\nWhen there isn't, we would have null values,\\nwhich is the case with both lebron James and\\nKyrie Irving.\\nHere, these are the main principles you need to\\nunderstand when deciding whether to create a\\nleft, right,\\ninner or outer join in tableaux depending on\\nyour needs.\\nAnd on the specific case you are working on,\\nyou will be able to apply one of these\\nstructures and join your data.\",\n",
              " \"Hello and welcome back.\\nNow that we are nearly finished with our\\nintroduction to Tableau.\\nIt is time to start creating great looking\\ncharts and use them to build a complete\\ndashboard.\\nThis is way more exciting than getting\\nacquainted with Tableau's interface.\\nIsn't it to do that?\\nWe'll solve a complete real life exercise and\\neach lesson will build upon the previous one.\\nSounds great. Right.\\nAll right.\\nThen let's get started.\\nHere's the Excel data we'll use.\\nIt was provided by a company that has produced\\nseveral audio books and has been selling them\\nat an online marketplace.\\nOne of the main components of that marketplace\\nis reviews.\\nSo we have two files, one about sales and\\nanother one containing information aboutreviews.\\nCustomers left for each audio book,\\nboth files contain the date when a purchase or\\na review occurred.\\nIt will be great if we manage to produce a\\ntable that takes advantage of both types of\\ndata we have when a person bought an audiobook\\nand when and with which rating a\\nperson left a review.\\nIf we manage to do that, we'll be able to\\ncreate several different charts in Tableau that\\nwould allow us to learn if the number of\\nreviews the company receives has been growing.\\nHow did the average review score change over\\ntime?\\nWhat is the percentage breakdown between 10\\nstar, nine star,\\neight star and other types of reviews?\\nWhat percentage of people acquiring an\\naudiobook?\\nLeave a review, visualize the correlation\\nbetween audiobook sales and number of\\nreviews or perhaps visualize the correlation\\nbetween average review score and sales\\nin the lessons to come.\\nYou'll see how to do all of that.\\nStay tuned and thanks for watching.\",\n",
              " \"All right, very good.\\nLet's take a look at the following picture.\\nThis is where we want to get by the end of our\\nexercise.\\nOur goal is to create a dashboard containing\\nthree charts,\\na chart showing us the number of reviews with a\\nsecond axis measuring the monthly average score.\\nThen we would like to create a pie chart\\nshowing us the percentage of reviews each\\naudiobook obtained.\\nFor example, 50% audiobook,\\n1 25% audiobook, 2 10% audiobook three and so\\non.And finally, we would like to create a chart\\nthat gives us information about the ratio\\nbetween reviews left and the number of\\naudiobook purchases.\\nSuch a visualization would help us understand\\nwhat portion of people buying an audiobook,\\nlisten to it and then leave a review. Ok.\\nThese three charts will be the foundation of\\nthe dashboard we will create later on.\\nAnd I've added a note on the side showing us\\nthat once the dashboard is ready,\\nwe will be able to look at the aggregate data\\nor use a filter to monitor the performance of\\nindividual audio books.\\nSounds exciting, right?\\nAs a side note here, I would like to add that\\nin general,\\nit is a good practice to sit down and design\\nyour dashboards before you start working in\\ntableaux.\\nThis allows you to have a predefined idea of\\nwhat you would like to achieve and to check\\nwhether you are able to do that at the end.\\nMoreover, and what is probably most important,\\nthis allows you to think what visualizations\\nmake sense from a business perspective.\\nOK, great.\\nLet's get right into it in our next lesson.\",\n",
              " \"As usual.\\nThe first thing we need to do when starting a\\nnew project is load our data.\\nOur two source files are audiobook reviews and\\naudiobook sales.\\nLet's connect them to Tableau.\\nHere's the audio book reviews file in the same\\nfolder.\\nWe also have the audiobook sales file.\\nWe'll need both.\\nSo I'll click on add and we'll load the other\\nfiles too in order to be able to use the\\ninformation of both tables at the same time,we'll have to combine them somehow to do that.\\nWe must double click at the audiobook\\nsales gray button that is in front of us.\\nThen we can drag the audiobook reviews\\ntable from the sheets field on the left.\\nWe've just created the join.\\nWe need excellent what we want to obtain by\\ndoing that is a unique table containing\\ninformation about all transactions for all\\naudio books and the respective reviews left by\\nclients whenever they chose to do so,\\nthe transaction ID column is the perfect link\\nbetween the two files as it is available\\nin both.\\nAnd it could serve as a common field based on\\nwhich we could link the two tables together.\\nSo one of the main aspects we'll explore in\\nthis lesson is how to create a connection\\nbetween two tables in tableaux.\\nPlease remember that we will distinguish the\\nterms data connection and table connection.\\nTable connection is performed by\\nfunctionalities like joining or blending.\\nIt refers to combining data from two or more\\ndata sources.\\nData connection instead represents a single\\ndata source connection between Tableau\\nand a data source such as an Excel workbook or\\nan SQL database.\\nWhen we imported the second file Tableau did\\nsome work for us in the background and created\\na connection between the two files.\\nThe symbol you see here is an indication we've\\ncreated an inner join.\\nTechnically speaking, when creating a join,\\nTableau sends a query to the database,\\nthe joint is implemented on the relevant tables\\nat the database level and the output of the\\noperation is brought back to Tableau where it\\nis ready to be used for analysis.\\nAnd inner join means that the two tables we've\\nadded have a field in common and we\\ncan combine them using that field.Let me hover my mouse over the symbol tableau\\nindicates that it has created an inner\\njoin using the parameter audiobook name.\\nWe don't want that.\\nWe want to link the two tables according to the\\ntransaction id parameter.\\nAs our analysis will be focused on user sales\\nand reviews.\\nSo I'll click on the inner join symbol and\\nwe'll open the join menu first\\noff.\\nLet me substitute the field we use.\\nIn order to create a connection between the two\\ntables, I would like to create a connection\\nusing the transaction ID field.\\nAnd here we are, here's a preview of the table\\nwe've created through an inner join and\\ntransaction ID as the primary key as shown in\\nthe diagram.\\nWhen we create an interj join between the two\\ntables, we consider their intersection the\\nsituation where the primary key is found in\\nboth tables.\\nTo give you an example, if a person who has a\\ngiven transaction ID purchased a course\\nbut did not leave a review, then they won't be\\nincluded in this table.\\nAnd inner join would require users who have\\npurchased a course to have left a rating\\nand both the date of purchase and the date when\\nthe rating was posted to be known.\\nBasically, it contains only the rows in which\\nwe have a transaction ID,\\na date of purchase, a date of review, a review\\nrating and information regarding which was the\\naudio book that was purchased and rated.\\nFor example, all the cases when a person bought\\nan audio book but did not rate,\\nit are not considered.\\nDo you think this information is important?\\nDo we want to be able to understand how reviews\\nimpacted sales and whether we can see a\\npattern in total purchases with respect toreviews?\\nOf course, we'll need this information.\\nAnd if we use an inner join, we are not going\\nto have it.\\nTherefore, we'll need a different type of join.\\nOne that includes the information about\\npurchases and people who did not rate an audio\\nbook.\\nSo looking at the tiny diagram we have here,\\nI am going to select a left join.\\nGiven that the audiobook sales file is on the\\nleft side.\\nWe want to have a table that contains\\ninformation regarding audiobook purchases,\\nall of the audiobook purchases.\\nAnd the case is when people who bought these\\nbooks provided a rating and a left join is more\\nsuitable than an inner join in\\nthis case.\\nOk, great.\\nIn our next lesson, we'll make a check to see\\nwhether the data we've connected to Tableau is\\ncorrect.\\nThis will do for now.\",\n",
              " \"Right.\\nOur pace is excellent.\\nIn this lesson, we would like to make sure that\\nthe data we've loaded through a join is truly\\nrepresentative of the figures we have in the\\ntwo source files,\\nright?\\nLet's open sheet one and do a few checks.\\nFirst off, I would like to see how many sales\\ntransactions were registered in total.\\nLet's drag the number of records field into the\\nworkspace area.\\nTableau is really quick and tells us that there\\nare 110,570 rows\\nwith transaction ID information.\\nThese are the actual sales of audio books that\\noccurred throughout the entire period ofanalysis.\\nA quick look into the sales Excel file shows us\\nthat this number is precisely the one we should\\nhave.\\nOk, let's change the format of the date of\\npurchase field to date,\\nshall we?\\nI like it much better up here among the\\ndimensions fields and with a calendar icon\\nright next to it,\\nsuggesting this is a date field.\\nNext, I'll test for the number of ratings we\\nhave in the reviews file.\\nI'll simply drop the ratings field into the\\nworkspace area and the result we have is\\n96,897 which is too high.\\nWhy is that?\\nWell, we are summing not counting,\\nthis is the actual sum of all ratings that have\\nbeen left by students.\\nWe want to count the number of ratings instead.\\nHere, that's much better.\\nPeople who bought our audio books left a total\\nof 10,798 ratings.\\nLet's make sure that this number is fine as\\nwell.\\nOk, here it is very well.\\nOne final check and we are good to go.\\nLet's add the date of purchase field to the\\ncolumns of our workspace.\\nMoreover, I'll increase the level of\\ngranularity of our data and we'll opt for a\\nmonthly breakdown.\\nThat's something we can do fairly easily and is\\none of Tableau's strongest features.\\nGranularity is a term that you will encounter\\nquite often while working with Tableau.\\nIt is very important to understand what it is\\nused for.\\nIn fact, it simply refers to the following the\\nlevel of detail in a field of a data set.\\nIn our example, this means taking a daily,\\nweekly, monthly or yearlybreakdown are all different levels of\\ngranularity of the date of purchase field of\\nthe audiobook sales data source.\\nHere's the monthly breakdown of reviews.\\nWait, there is something strange according to\\nTableau, we did not receive any\\nreviews in December 2017.\\nHowever, I do know for a fact that we did.\\nHere's the proof in our Excel file.\\nWhat happened?\\nTableau gets confused pretty easily when we\\njoin the data and then use a dimension\\nsuch as purchase date from the sales file and\\nanother field such as rating from the reviews\\nfile.\\nFor some reason, the date fields of the two\\ntables we joined do not match up with each\\nother correctly.\\nWhenever you experience such issues, it is best\\nto use data blending and alternative to\\ntableau joints.\\nThat's precisely what we will do in our next\\nlesson.\\nThanks for watching.\",\n",
              " \"Data blending is a method of combining data\\nthat supplements a table of data from one data\\nsource with columns of data from another data\\nsource.\\nIn our case, we would combine the sales data\\nfrom the audiobook sales file with the\\nratings column from the audiobook reviews file.\\nHow does blending differ from joining?\\nYou can think of a data blend as a specific\\ntype of left joint that is preferable or\\nnecessary to be applied depending on various\\nconditions.\\nSometimes using a joint will do a perfect job\\nwhile in other situations blending will either\\ndeliver better or quicker results or be the\\nonly solution.\\nMoreover joining data is something you domanually.\\nWhereas data blending is a functionality that\\ntableau implements automatically\\nwhile you are working on your sheet.\\nThis makes it a more intuitive feature to use\\nprovided that the following conditions are met.\\nBoth data tables are separate data sources.\\nThere is a field that serves as the connection\\nbetween them and would allow us to carry out\\nqueries that leverage information from both\\ntables.\\nSo one of the preliminary basic requirements to\\nblend data in tablet is to have a common field\\ncreating the connection between the two\\ndata tables.\\nFrom a technical perspective.\\nWhat blending does is take separate query\\nresults from each data source and\\naggregate them in the view that is in Tableau\\nonly then it will\\nconnect and join the query results on the same\\ncommon field which should contain information\\nof the same data type.\\nThis is different from the case when you are\\nusing a joint where the aggregation is\\nhappening at the database level and just the\\noutput of the joint is being brought back to\\ntableau when blending, the aggregation occurs\\nin tableau.\\nSo what are the benefits of blending data?\\nIt turns out that joining or blending can bring\\ndifferent results.\\nAnd here is the tricky part.\\nIf you join two data tables containing\\nduplicate values that are not aggregated\\nproperly in while doing some preliminary work\\non the data, you will obtain an artificially\\ninflated data set in tableaux\\nblending solves that problem automatically\\ntableau will consider the level of granularity\\nyou have chosen in the view in other words, in\\nyour sheet and will combine the data sources\\nwith aggregated fields directly.OK?\\nI think we are ready to create an actual blend\\nin tableaux.\\nLet's open the audiobook sales file first.\\nThen once I've opened the file, I'll open a\\nsheet and click on new data source from the\\ndata tab.\\nThis is how we will create a new data\\nconnection and we load both files at the same\\ntime without creating a joint.\\nAs we can see here, both files are open in\\nTableau to make sure we've created a blend.\\nI can open the edit relationships, dialogue box\\nand see whether tableaux has created a\\nconnection between the two files.\\nIn our case, things are pretty straightforward\\nbecause Tableau immediately recognized that the\\ntwo files contain columns with the same name,\\ntransaction ID.\\nThe primary data source is the audiobook sales\\nfile which is excellent.\\nThis means it would represent the left table of\\nthe left join performed while blending the\\ndata tableaux.\\nOr alternatively, the view will use all rows\\nfrom audiobook sales audiobook review instead\\nacts as a secondary data\\nsource, the right table.\\nTherefore, while blending tableau will use the\\naggregated rows from this data source based on\\nthe dimension of the common fields.\\nFor the sake of exercise.\\nLet's select the custom relationship radio\\nbutton and choose not one but two different\\nfields that serve as the connection between the\\ntwo files.\\nThis is similar to having a two column,\\nprimary key and a two column foreign key in SQL.\\nI'll click on add\\nand then would like to connect the date of\\nreview and the date of purchase.\\nHm I can't see the date of purchase in here.\\nWhat is the reason?Well, Tableau didn't recognize that this is a\\ndimension and added this field\\namong measures.\\nLet's change its data type and open the edit\\nrelationships window and select to add a\\nnew custom relationship which connects the two\\nfiles based on the date of purchase and on\\nreview date.\\nAnd that's how we edit the relationship\\ntableaux created.\\nRight?\\nLet's switch back to the automatic connection\\ntableau created in our next video.\\nWe'll test whether blending solved the problem\\nwe experienced earlier.\\nHopefully we will be able to combine sales and\\nreviews without any problems.\\nStay tuned.\",\n",
              " \"Now that we have created a blend, we can go\\nahead and make a quick check.\\nThat would allow us to see if the numbers we\\nwill work with.\\nLook fine this time.\\nLet's start with the number of sales\\ntransactions.\\nFirst, I'll simply drag the measure values\\nfield into the workspace area.\\n110,570.\\nPrecisely what we expected. Good.\\nThe number of sales transactions is the one we\\nexpected.\\nNext, I'll remove this field and open the\\naudiobook reviews data to check the number of\\nratings we have,\\nI'll simply drag and drop the rating field.\\nBut this time tableaux displays an error.\\nIt tells us that fields cannot be used from the\\naudiobook reviews data source because there is\\nno relationship to the primary data source.\\nWe find out our data is not blended yet\\nto do that.We have to click on the tiny link icon right\\nnext to transaction id and choose this to be\\nour linking field.\\nThe error we observed previously is not going\\nto appear again because our two data sources\\nare properly linked now. Great.\\nThis is a field that shouldn't be summed but\\ncounted as we are interested in the number of\\nratings left by students and not by the total\\nsum of their ratings.\\n10,798.\\nAgain, the number we expected to see it's time\\nfor the true test.\\nThese numbers were ok.\\nThe last time too,\\nremember, let's plot the number of reviews and\\nthe date of purchase field from the\\naudiobook sales file.\\nAll I have to do is add date of purchase in\\ncolumns and then choose a monthly breakdown\\ninstead of annual breakdown.\\nOh, no, December 2017 is empty again.\\nWhat can we do now?\\nBlending doesn't work either.\\nLet's have some faith.\\nWe'll figure it out.\\nI'll go to data and open the edit relationships\\nmenu here,\\nwe can choose the primary data source which\\nshould be audiobook sales and the fields that\\nserve as a link between the two files.\\nLet's opt for a custom selection and add the\\nfollowing fields.\\nFirst, I'll link the year of review date with\\nthe year of purchase date and\\nthe month of review date with the month of\\npurchase date.\\nOnce we are ready, we can click.\\nOk, and see if the situation changed the same.\\nCheck the count of number of reviews with\\nrespect to purchasing date will show us whether\\nwe've managed to solve the problem by using a\\ndifferent linking field and it appears that ithas here's a timeline that shows the number of\\nratings left each month.\\nWe have 653 reviews for December, not zero.\\nAnd that's excellent. Wow.\\nIt took us a while,\\nbut we figured it out.\\nWe had to edit relationships and adjust the\\nfield that serves as a link between the two\\nfiles.\\nOtherwise we would have been left with a wrong\\ngraph.\\nAnd that would be unacceptable in a\\nprofessional environment as wrong\\nvisualizations lead to wrong business insights\\nin our next lesson.\\nWe'll create the first chart for our dashboard.\\nThanks for watching.\",\n",
              " \"Ok, excellent.\\nWe are ready to start with the first chart that\\nwill be inserted in our dashboard.\\nTherefore, I'll rename the worksheet's name to\\nchart one.\\nOk, good.\\nLet's add the date of review information into\\ncolumns and this is where we will be able to\\nsee the timing of purchases and reviews.\\nAs usual,\\nwe are interested in a breakdown by months.\\nSo I'll select month, the workspace area shows\\nus that review dates\\nrange from February 2017 to February 2018,\\nwhich\\nis what we expected to see.\\nLet's insert some data, shall we first?\\nI'll add the number of ratings using the count\\nfunction.\\nEverything's fine and we have data for December\\n2017.\\nSo we can forget about that problem.\\nAccording to our initial plan, this will be a\\nchart that shows the number of reviews and theaverage review score per month displayed on a\\nsecondary axis.\\nSo I'll add the rating field to rose for the\\nsecond time.\\nBut this time we want the average of these\\nnumbers and we would like to create a dual axis.\\nExcellent.\\nObviously, we will have to fine tune the axis\\nscale.\\nA bit as right now, the chart doesn't show a\\nmatch.\\nI'll simply double click and choose a fixed\\nrange starting from eight and going all the way\\nup to 10,\\nwhich is the maximum review score we can have.\\nHowever, right now, the two charts overlap in a\\nstrange way and we are unable to see their\\ntrends.\\nSo I'll increase the size of the axis to 12 and\\nwe'll change the full color of both variables,\\nnumber of ratings and average ratings.\\nThat's easy to do.\\nI need to select one of the two variables and\\nthen click on the color button under marks.\\nOnce we've opened the edit colors menu, we can\\nchoose which variables color we would like to\\nchange to a color.\\nWe like better.\\nI like yellow and blue. Awesome.\\nI'm not really a fan of opacity which adds a\\ntransparency effect and sort of mixes the\\ncolors we have in our chart.\\nTherefore, I'll opt for 100% opacity for both\\nvariables.\\nSee the chart looks nicer.\\nLet's edit its axis again.\\nThat's something which is quite easy to do.\\nWe have to double click on a specific axis and\\ntype the axis title we would like to have,\\nI'll change counter rating to number of ratings,\\nmonth of review date,\\ntwo month.\\nAnd I believe the average rating doesn't needto be changed.\\nVery good.\\nThis is our first chart.\\nDoes it give us any meaningful information?\\nWell, yes, I believe it does.\\nFirst off, we can see that the number of\\nreviews left by people has been increasing,\\nwhich is pretty great.\\nThe average review score is almost nine and\\nsometimes even higher than nine,\\nwhich is a pretty high score but should be\\ninterpreted.\\nAnd compared with the rest of the market.\\nMoreover, we don't see a dependence between\\nnumber of reviews and average ratings,\\nwhich means that average review scores are not\\ninfluenced by the number of people leaving\\nreviews.\\nAll of this is quite interesting.\\nLet's keep up the good work we have been doing\\nin our next lesson when we will create the\\nsecond chart for our dashboard.\\nThanks for watching.\",\n",
              " \"Hi and welcome back in this video.\\nWe'll create the second chart which will be\\npart of our dashboard a pie chart showing the\\npercentage of the total reviews that each\\naudiobook obtained.\\nThe number of reviews is quite important in the\\nmarketplace we are studying and this is the\\nreason why we are interested in finding out\\nwhich audiobooks collected more reviews and\\nalternative visualization would be a pie chart\\nshowing us the percentage of people who\\npurchased a given audio book. Ok.\\nGiven that we know what we would like to\\naccomplish things should be easier, right?\\nI'll add the rating field to the workspace area.\\nThe number we obtained is the sum for all\\nratings.\\nLet's use count for this measure. Perfect.The total number of reviews is\\n10,798.\\nAnd we know for a fact that that is true.\\nLet's go ahead and add the audiobook names\\ndimension above the rating field, shall we?\\nThis creates a breakdown by audiobook exactly\\nwhat we want to have.\\nNow, I can simply select the pie chart icon\\nwithin the show me functionality and I'll\\ncreate a pie chart, a really tiny one but still\\na pie chart to increase the charts\\nsize.\\nI can simply click anywhere in the workspace\\narea, hold the control key and then use the\\narrow keys.\\nIf I press control and up the chart grows\\nvertically while control and right\\narrow increases the charts size horizontally,\\nthe opposite is true as well.\\nWe can decrease the charts size by pressing\\ncontrol and down key or control and left\\narrow. Awesome.\\nWhat else we need labels?\\nRight?\\nOtherwise, it is difficult to gain an idea what\\nportion of overall reviews a specific\\naudiobook accounted for.\\nI'll drag the rating field in label and a\\nnumber of reviews appears right next to each\\naudio book.\\nAgain, we need the count of ratings and not the\\nsum.\\nOk.\\nBut how do we display these as a percentage?\\nThat's not that difficult.\\nActually, all I have to do is go to analysis,\\nselect percentage of and then click on table.\\nBoom.\\nHere we are.\\nThese are the percentages each audiobook\\naccounted for among the total number of reviews,\\nthe pie charts and the labels we added shows us\\nthat audio books, one and two accounted formore than 50% of the total number of\\nreviews the company received.\\nVery interesting.\\nThe business relies greatly on these best\\nsellers.\\nIn our next lesson.\\nWe'll create the third and final chart that\\nwould allow us to complete our initial plan and\\nobtain the dashboard we intended from the very\\nbeginning\",\n",
              " \"Ok, we are almost there ready for chart number\\nthree.\\nI hope you are.\\nHere we go.\\nIn this lesson.\\nWe would like to create a chart that gives us\\ninformation about the ratio between reviews\\nleft and the number of audiobook\\npurchases in a given month.\\nAn important KP I showing us whether people who\\nbuy audiobooks leave reviews to do that.\\nWe'll need to create a few calculated fields.\\nFirst, let's create a field which counts the\\nnumber of ratings,\\nnot the sum of all ratings, but their count.\\nIt will be much easier if we create this field\\nand use it going forward.\\nThe name of the field we are creating is number\\nof ratings and I simply need to use the\\ncount function.\\nThe next calculated field I would like to\\ncreate is number of purchases.\\nLet's change the data source.\\nWe've selected to audiobook sales here.\\nI will create a field called number of\\npurchases which will contain the number of\\naudiobook sales the company made.\\nHow do I count the number of purchases?\\nWell, the transaction ID code is unique, right?\\nIf we count it, we should obtain the number of\\nsales transactions which is precisely what weare looking for.\\nOk, good.\\nWe are almost ready now, we can create the last\\ncalculated field which will be the ratio\\nbetween reviews and new purchases.\\nLet's do that.\\nIt is a fairly easy task given that we've\\nalready created the number of reviews and the\\nnumber of purchases all we have to do is divide\\nthe two figures and we'll obtain the measure we\\nwant to plot from the very beginning.\\nLet's add it to the rows of our visualization.\\nThe result is a pretty nice bar chart which is\\na bit too large but still looks meaningful.\\nIt appears that the ratio of ratings to new\\nstudents was significantly lower in November\\n2017 and way higher the month before three\\ntimes lower to be precise.\\nI am sure the firm's Business intelligence team\\nwould want to have a look at that and analyze\\nwhat the reason is for this.\\nLet's quickly edit the title of the horizontal\\naxis to month and save our work\\nin our next lesson.\\nWe'll organize the charts we created in a\\ndashboard.\\nStay tuned and thanks for watching.\",\n",
              " \"Congratulations on making it this far in our\\nTableau training.\\nLet's take a moment to see how much we have\\ncovered to this point.\\nWe started off by learning when and how Tableau\\ncan be useful in corporate decision making and\\nlearned how to install Tableau's free version\\nTableau public.\\nWe then learned how to connect data to Tableau\\nand what we can do with the different parts of\\nthe Tableau interface.\\nNot long after we created your first Tableau\\nchart, we learned how to duplicate sheets\\nand how to create tables.Then we learned how to create custom fields in\\norder to manipulate our data within tableau\\neasily.\\nIn addition, we learned how to add totals and\\nsub totals to our tables and how to work with\\nfilters.\\nWe explored functionalities allowing us to work\\nwith multiple data sources such as joins and\\ndata blending.\\nAnd most recently, we created three meaningful\\ncharts.\\nNow we are going to build our dashboard which\\nwill be the last piece of the puzzle really.\\nIt will be interesting to put all three charts\\nright next to each other and see the type of\\ninsights we can get by analyzing them in one\\nplace.\\nOK.\\nLet's get right into it to create a new\\ndashboard.\\nI'll click on the tiny icon we have here.\\nSee when we hover the mouse over it, it starts\\ndisplaying new dashboard.\\nOnce the dashboard has been created, my first\\ntask would be to modify its size right now.\\nIt is a bit too small, isn't it?\\nI can adjust the size settings from the left\\npart of the dashboard screen.\\nLet's work with a range that is 1000 pixels\\nwide and has a height of 800 pixels.\\nI hope you are watching this video from a large\\nscreen.\\nOK.\\nLet's drag and drop the three charts.\\nAll I have to do is drag them and place each\\nchart where I want it.\\nTableau is quite smart and manages to find\\nspace and guesses what we want to do when\\nwe position the cursor above the dashboard area.\\nOf course, there are a few things that need to\\nbe adjusted.\\nI'll remove the legends.\\nWe don't need leaving the audiobooks legend.Only moreover, I would like to place the\\naudiobook legend below the pie chart.\\nIt belongs to this way.\\nWhat we are doing will be much clearer.\\nI'll simply press on the legend and then grab\\nthe part you see here,\\ndragging it below the pie chart.\\nLet's resize a bit to get rid of the arrows.\\nPerfect.\\nNow, to remove the arrows of the pie chart and\\nfit it in its allocated space without any\\nproblems we'll need to adjust its size from the\\nchart to sheet.\\nLet's go there and reduce the pie charts size\\njust a tiny bit horizontally and vertically\\nand then we can go back to the dashboard sheet\\nand see what happened.\\nOk, great.\\nThe arrows disappeared.\\nWe are one step closer.\\nLet's change the chart titles a bit because\\nfrankly, they don't mean that much.\\nWe should have done it earlier, but better late\\nthan never.\\nRight.\\nA good title for the first chart would be\\nnumber of reviews and average rating.\\nAlso, I would like to adjust its font size to\\n11 and put the text in bold.\\nWe'll do the same for the other charts too in\\norder to be consistent,\\nwhich is quite important.\\nWhen building a dashboard,\\nthe title of the pie chart would be number of\\nreviews by audiobook,\\nas promised, I'll apply a font size of 11 and a\\nbold text effect.\\nAnd lastly, the title of the third chart will\\nbe ratio of reviews to sales\\nvery well.\\nOur dashboard is almost ready in our next\\nlesson.\\nI will show you how we can add a filter andmake this a truly interactive tool that allows\\nus to dig deeper and filter all three charts.\\nContemporaneously.\",\n",
              " \"Ok, guys, we are almost there.\\nOur goal in this lesson would be to add a\\nfilter to our data and be able to look at the\\ndashboard and choose which audio books we would\\nlike to analyze and simply select them from the\\nfilter.\\nSounds useful, right?\\nThe data we see here is quite meaningful and\\nshows us some important trends.\\nHowever, actionable decisions will probably\\nhave to be made at the audiobook level and will\\nneed to be specific for each of the audiobooks\\nour firm sells addressing the story we see here.\\nAll right, let's add a filter to chart number\\ntwo, the pie chart.\\nI'll simply click on the tiny arrow in its\\nright corner containing more options and we'll\\napply audiobook name as a filter again.\\nWe'll have to adjust the charts,\\nsize and position in the dashboard a bit to\\nremove the arrows very well.\\nI think this will do.\\nNow when I use the filter,\\nall changes that occur are for the pie chart,\\nonly the other two charts remain intact as the\\nfilter we just added has no power over them at\\nthe moment.\\nAnd we want to be able to use this filter in\\norder to modify the entire dashboard and not\\nonly one of its charts, how do we do that?\\nLet's select the tiny arrow in the upper right\\ncorner of the filter and go to apply to\\nworksheets where we will be able to click on\\nselected worksheets in the dialog box that\\nopens, I can easily add chart one and chart\\nthree and then press\\nOK.\\nI hope the filter makes changes to all threecharts now.\\nAnd yes, it does nice.\\nHowever, one thing is a bit suspicious when I\\nUN filter the first few audio books,\\nthe ratio of reviews to sales continues to\\ndecrease.\\nAnd this makes no sense.\\nIt appears that right now the ratios are all\\ncalculated with respect to the total number of\\naudio books. Hm.\\nThat's strange.\\nLet's check.\\nI suspect something is not as it should be when\\nI go and take a look at the other two\\ncharts.\\nI see that the blending connection has not been\\nactivated for the audiobook name field.\\nLet's activate the connection for both and see\\nif this changes things.\\nNow when I unfiltered the first few audiobooks,\\nthe percentage doesn't decrease,\\nbut it even goes up.\\nI believe it's fine.\\nNow, please bear in mind the following.\\nIf I would like to use some of the charts\\nelements as a filter,\\nall I have to do is select, use as filter in\\nthe upper right corner of a chart and then\\nall three charts will be updated.\\nThis is another way to play around with filters,\\nwhether we filter data from the actual filter\\nor simply click on a given chart element.\\nIt doesn't make much of a difference in both\\ncases.\\nA filter will be applied.\\nWe've constructed a dashboard that can easily\\nbe filtered and unfiltered from here.\\nNow, we can explore the relationship between\\ndifferent audio books,\\nthe number of reviews they received their\\naverage score and the ratio between reviews and\\naudiobook sales.\\nThat's awesome play around with the data and donot hesitate to share with us the insights you\\nmanaged to uncover great job getting to the end\\nof this exercise.\\nIt was a real pleasure teaching you tableau and\\nwe hope to see you soon in some of our other\\nmodules until then a warm hug and thanks for\\nwatching.\",\n",
              " \"Hi, one many of you experience difficulties\\nwith this part of the exercise,\\ncreating filters in this video.\\nOur goal will be to shed some light and\\nhopefully clarify your doubts before applying\\nthe filter to all three charts.\\nYou need to make sure the blending connections\\nare working.\\nGo to chart one and click on data, edit\\nrelationships.\\nThen you need to make sure there is a relation\\nfor audiobook names.\\nOnce this is done, check for all three charts.\\nIf the blending connections are turned on,\\nthey need to be colored in red to make this\\ncheck, you need to click on the data source\\naudiobook sales and click on the icon next to\\nthe audiobook names.\\nOnce the connections are turned on, you will be\\nable to proceeded and add the filter.\\nWhat you need to do is select the pie chart\\nchart two and click on the tiny arrow in the\\nupper right corner.\\nThen select filter audiobook name.\\nIn order to use this filter to modify the whole\\ndashboard, you need to go to the right corner\\nof the dashboard where the audiobook names are\\nplaced again,\\nselect the tiny arrow and click on.\\nApply to worksheets,\\nthen select selected worksheets and mark all\\ncharts.\\nOk.\\nNow the filter should be working properly.Please make a check and see.\\nThat's the case in your own workbook too.\\nThanks for watching.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "string_list_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "75d304c3",
      "metadata": {
        "id": "75d304c3"
      },
      "outputs": [],
      "source": [
        "PROMPT_FORMATTING_S = '''Improve the following Tableau lecture transcript by:\n",
        "- Splitting the text into meaningful paragraphs\n",
        "- Correcting any misplaced punctuation\n",
        "- Fixing mistranscribed words (e.g., changing 'tableaux' to 'Tableau')\"\n",
        "'''\n",
        "\n",
        "PROMPT_TEMPLATE_FORMATTING_H = '''This is the transcript:\n",
        "{lecture_transcript}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9b90e779-12cb-4c0b-b33f-38afacd634e3",
      "metadata": {
        "id": "9b90e779-12cb-4c0b-b33f-38afacd634e3"
      },
      "outputs": [],
      "source": [
        "prompt_formatting_s = SystemMessage(content=PROMPT_FORMATTING_S)\n",
        "prompt_template_formatting_h = HumanMessagePromptTemplate.from_template(template=PROMPT_TEMPLATE_FORMATTING_H)\n",
        "\n",
        "chat_prompt_template_formatting = ChatPromptTemplate(messages=[prompt_formatting_s,\n",
        "                                                               prompt_template_formatting_h])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d3293c74-ad9f-4206-9105-7a6809269206",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "d3293c74-ad9f-4206-9105-7a6809269206",
        "outputId": "206e63c1-3bce-4680-b4f6-c17d808295f1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3578935414.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m chat = ChatOpenAI(model_name='gpt-4o', \n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m365\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   temperature=0)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m  \u001b[0;31m# noqa: D419  # Intentional blank docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m                 \u001b[0;34m\"api_key\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0masync_api_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             }\n\u001b[0;32m-> 1021\u001b[0;31m             self.root_async_client = openai.AsyncOpenAI(\n\u001b[0m\u001b[1;32m   1022\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0masync_specific\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(model_name='gpt-4o',\n",
        "                  seed=365,\n",
        "                  temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "70f2c93e",
      "metadata": {
        "id": "70f2c93e"
      },
      "outputs": [],
      "source": [
        "str_output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "beeb2041",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "beeb2041",
        "outputId": "bd38a63d-33c6-4e71-ecb5-2947daa875ae"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'chat' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3117469989.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m chain_formatting = (chat_prompt_template_formatting \n\u001b[0;32m----> 2\u001b[0;31m                     \u001b[0;34m|\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                     | str_output_parser)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'chat' is not defined"
          ]
        }
      ],
      "source": [
        "chain_formatting = (chat_prompt_template_formatting\n",
        "                    | chat\n",
        "                    | str_output_parser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "24896acd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "24896acd",
        "outputId": "8b8e8700-2481-4a9e-cb78-a8ca9b03d345"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'chain_formatting' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-235798784.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstring_list_formatted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain_formatting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_list_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'chain_formatting' is not defined"
          ]
        }
      ],
      "source": [
        "string_list_formatted = chain_formatting.batch(string_list_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e6822f05-2db3-424a-a47a-216d8a9d44e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "e6822f05-2db3-424a-a47a-216d8a9d44e9",
        "outputId": "48c77c8f-168b-4b6e-e1de-6cf59b4536e8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'string_list_formatted' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4238884656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstring_list_formatted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'string_list_formatted' is not defined"
          ]
        }
      ],
      "source": [
        "string_list_formatted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26aaa8f0",
      "metadata": {
        "scrolled": true,
        "id": "26aaa8f0"
      },
      "outputs": [],
      "source": [
        "for i in string_list_formatted:\n",
        "    print(i)\n",
        "    print('''\n",
        "-------------------\n",
        "    ''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "852deccd",
      "metadata": {
        "id": "852deccd"
      },
      "outputs": [],
      "source": [
        "for i, j in zip(docs_list_md_split, string_list_formatted):\n",
        "    i.page_content = j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de652a59",
      "metadata": {
        "scrolled": true,
        "id": "de652a59"
      },
      "outputs": [],
      "source": [
        "for i in docs_list_md_split:\n",
        "    print(i.page_content)\n",
        "    print('''\n",
        "-------------------\n",
        "    ''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72702001",
      "metadata": {
        "id": "72702001"
      },
      "outputs": [],
      "source": [
        "len(docs_list_md_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d7ce01f-d8d4-4adf-8184-6e1c61d35bf3",
      "metadata": {
        "id": "6d7ce01f-d8d4-4adf-8184-6e1c61d35bf3"
      },
      "source": [
        "### Split the Lectures with TokenTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c28555be-fe0e-430d-9944-c35da545c82c",
      "metadata": {
        "id": "c28555be-fe0e-430d-9944-c35da545c82c"
      },
      "outputs": [],
      "source": [
        "token_splitter = TokenTextSplitter(encoding_name=\"cl100k_base\",\n",
        "                                   chunk_size=500,\n",
        "                                   chunk_overlap=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c5c92b-e85f-43c3-a52e-0d622c21a333",
      "metadata": {
        "id": "54c5c92b-e85f-43c3-a52e-0d622c21a333"
      },
      "outputs": [],
      "source": [
        "docs_list_tokens_split = token_splitter.split_documents(docs_list_md_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bd31047-5292-477c-bbaa-b59a37183e4b",
      "metadata": {
        "id": "8bd31047-5292-477c-bbaa-b59a37183e4b"
      },
      "outputs": [],
      "source": [
        "len(docs_list_tokens_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2edb97",
      "metadata": {
        "id": "3d2edb97"
      },
      "source": [
        "### Create Embeddings, Vector Store, and Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b1488a",
      "metadata": {
        "id": "42b1488a"
      },
      "outputs": [],
      "source": [
        "embedding = OpenAIEmbeddings(model='text-embedding-3-small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5378ec56",
      "metadata": {
        "id": "5378ec56"
      },
      "outputs": [],
      "source": [
        "# vectorstore = Chroma.from_documents(documents = docs_list_tokens_split,\n",
        "#                                     embedding = embedding,\n",
        "#                                     persist_directory = \"./intro-to-tableau\")\n",
        "\n",
        "vectorstore = Chroma(persist_directory = \"./intro-to-tableau\",\n",
        "                     embedding_function = embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21448a5f",
      "metadata": {
        "id": "21448a5f"
      },
      "outputs": [],
      "source": [
        "len(vectorstore.get()[\"documents\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef0a861",
      "metadata": {
        "id": "eef0a861"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_type = 'mmr',\n",
        "                                     search_kwargs = {'k':2,\n",
        "                                                      'lambda_mult':0.7})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45465253-b425-4074-a268-30c02064bdc5",
      "metadata": {
        "id": "45465253-b425-4074-a268-30c02064bdc5"
      },
      "source": [
        "### Create Prompts and Prompt Templates for the Q&A Chatbot Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c5823d",
      "metadata": {
        "id": "64c5823d"
      },
      "outputs": [],
      "source": [
        "PROMPT_CREATING_QUESTION = '''Lecture: {question_lecture}\n",
        "Title: {question_title}\n",
        "Body: {question_body}'''\n",
        "\n",
        "PROMPT_RETRIEVING_S = '''You will receive a question from a student taking a Tableau course, which includes a title and a body.\n",
        "The corresponding lecture will also be provided.\n",
        "\n",
        "Answer the question using only the provided context.\n",
        "\n",
        "At the end of your response, include the section and lecture names where the context was drawn from, formatted as follows:\n",
        "Resources:\n",
        "Section: *Section Title*, Lecture: *Lecture Title*\n",
        "...\n",
        "Replace *Section Title* and *Lecture Title* with the appropriate titles.'''\n",
        "\n",
        "PROMPT_TEMPLATE_RETRIEVING_H = '''This is the question:\n",
        "{question}\n",
        "\n",
        "This is the context:\n",
        "{context}'''\n",
        "\n",
        "prompt_creating_question = PromptTemplate.from_template(template=PROMPT_CREATING_QUESTION)\n",
        "prompt_retrieving_s = SystemMessage(content=PROMPT_RETRIEVING_S)\n",
        "prompt_template_retrieving_h = HumanMessagePromptTemplate.from_template(template=PROMPT_TEMPLATE_RETRIEVING_H)\n",
        "\n",
        "chat_prompt_template_retrieving = ChatPromptTemplate([prompt_retrieving_s,\n",
        "                                                      prompt_template_retrieving_h])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f24135-77cc-47cb-af41-bc2d4fa8d52a",
      "metadata": {
        "id": "f4f24135-77cc-47cb-af41-bc2d4fa8d52a"
      },
      "source": [
        "### Create the First Version of the Q&A Chatbot Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f57ff444-675e-4d77-a856-6d0fa535252f",
      "metadata": {
        "id": "f57ff444-675e-4d77-a856-6d0fa535252f"
      },
      "outputs": [],
      "source": [
        "chain_retrieving = (prompt_creating_question\n",
        "                    | RunnableLambda(lambda x: x.text)\n",
        "                    | {'context': retriever,\n",
        "                       'question': RunnablePassthrough()}\n",
        "                    | chat_prompt_template_retrieving\n",
        "                    | chat\n",
        "                    | str_output_parser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68bfec1f-8a2a-4603-b310-d4b43241db51",
      "metadata": {
        "id": "68bfec1f-8a2a-4603-b310-d4b43241db51"
      },
      "outputs": [],
      "source": [
        "result = chain_retrieving.invoke({\"question_lecture\": \"Adding a custom calculation\",\n",
        "                                  \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
        "                                  \"question_body\": \"This question refers to calculating the GM%.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc59d3c-a110-4f8b-9a23-516ef99d5089",
      "metadata": {
        "id": "abc59d3c-a110-4f8b-9a23-516ef99d5089"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "523192d0-3359-46d2-9793-5d787017891c",
      "metadata": {
        "id": "523192d0-3359-46d2-9793-5d787017891c"
      },
      "source": [
        "### Create a Runnable Function to Format the Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada2aa9f",
      "metadata": {
        "id": "ada2aa9f"
      },
      "outputs": [],
      "source": [
        "@chain\n",
        "def format_context(dictionary):\n",
        "\n",
        "    formatted_string = \"\"\n",
        "    retrieved_list = dictionary[\"context\"]\n",
        "\n",
        "    for i in range(len(retrieved_list)):\n",
        "        formatted_string += f'''\n",
        "Document {i+1}\n",
        "Section Title: {retrieved_list[i].metadata[\"Section Title\"]}\n",
        "Lecture Title: {retrieved_list[i].metadata[\"Lecture Title\"]}\n",
        "Content: {retrieved_list[i].page_content}\n",
        "\n",
        "-------------------\n",
        "'''\n",
        "\n",
        "    new_dictionary = {\"context\": formatted_string,\n",
        "                      \"question\": dictionary[\"question\"]}\n",
        "\n",
        "    return new_dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fef0e7",
      "metadata": {
        "id": "73fef0e7"
      },
      "outputs": [],
      "source": [
        "chain_retrieving_improved = (prompt_creating_question\n",
        "                             | RunnableLambda(lambda x: x.text)\n",
        "                             | {'context': retriever,\n",
        "                                'question': RunnablePassthrough()}\n",
        "                             | format_context\n",
        "                             | chat_prompt_template_retrieving\n",
        "                             | chat\n",
        "                             | str_output_parser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9198ec3d",
      "metadata": {
        "id": "9198ec3d"
      },
      "outputs": [],
      "source": [
        "result_improved = chain_retrieving_improved.invoke({\"question_lecture\": \"Adding a custom calculation\",\n",
        "                                                    \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
        "                                                    \"question_body\": \"This question refers to calculating the GM%.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935e8de2-a736-41ed-acfc-04addefd913c",
      "metadata": {
        "id": "935e8de2-a736-41ed-acfc-04addefd913c"
      },
      "outputs": [],
      "source": [
        "result_improved"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b19713-7830-4f6e-a424-3b8588d43efe",
      "metadata": {
        "id": "92b19713-7830-4f6e-a424-3b8588d43efe"
      },
      "source": [
        "### Stream the Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a64d90-f212-40b0-8d0d-a1cf90fceddd",
      "metadata": {
        "id": "01a64d90-f212-40b0-8d0d-a1cf90fceddd"
      },
      "outputs": [],
      "source": [
        "result_streamed = chain_retrieving_improved.stream({\"question_lecture\": \"Adding a custom calculation\",\n",
        "                                                    \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
        "                                                    \"question_body\": \"This question refers to calculating the GM%.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "666333e8-a79a-4de3-bada-15ada2f3644c",
      "metadata": {
        "id": "666333e8-a79a-4de3-bada-15ada2f3644c"
      },
      "outputs": [],
      "source": [
        "result_streamed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527f8838",
      "metadata": {
        "id": "527f8838"
      },
      "outputs": [],
      "source": [
        "for chunk in result_streamed:\n",
        "    print(chunk, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0984c9",
      "metadata": {
        "id": "fb0984c9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02873ff3",
      "metadata": {
        "id": "02873ff3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52db99b",
      "metadata": {
        "id": "f52db99b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bca3aaab",
      "metadata": {
        "id": "bca3aaab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88298d1",
      "metadata": {
        "id": "c88298d1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain_env_project",
      "language": "python",
      "name": "langchain_env_project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}